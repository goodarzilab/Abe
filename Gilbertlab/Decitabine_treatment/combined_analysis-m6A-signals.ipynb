{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We have already established that using annotated HeLa m6A sites, we can observe changes in genes with m6A sites (HL-60) cells. In order to confirm this m6A sites, we performed MeRIP-seq in treated and untreated cells, and did observe a general increase in m6A levels upon treatments for a large number of annotated sites. Here, our goal is to indpendently analyze the MeRIP data without relying on HeLa annotations and use it to define a **treatment-induced hyper-methylation sites**. We will then assess the location and behaviour of these targets across the other datasets generated in this study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test enrichment of treatment-induced hyper/hypo-methylation sites\n",
    "\n",
    "### Goal\n",
    "Here, I aim to identify the genes that are hyper or hypo methylated as genesets, and see if they have enriched accross all genes; the input table is list of genes with control vs. treated fold change of RNA expression, RNA stability and translational efficiency. \n",
    "### Steps \n",
    "1. Prepare inputs  \n",
    "    - Filtering genes with $\\Delta$methylation >= 2 as hyper-methylation sites\n",
    "    - Filtering genes with $\\Delta$methylation <= -2 as hypo-methylation sites\n",
    "    \n",
    "2 to 1\n",
    "\n",
    "include pvalue... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def two_sided_mtyl(fcthr=1,pvthr=0.01):\n",
    "    delta_mtyl = pd.read_csv('meRIP-seq/hl60_delta_mtyl_table.txt', sep='\\t')\n",
    "    ### hyper_methylation gene list\n",
    "    # subset by threshold \n",
    "    hyper = delta_mtyl.iloc[np.where([(l and p) for l,p in zip(delta_mtyl.logFC >= fcthr,delta_mtyl.p_value < pvthr)])]\n",
    "    ### hypo_methylation gene list\n",
    "    # subset by threshold - logFC <= -2\n",
    "    hypo = delta_mtyl.iloc[np.where([(l and p) for l,p in zip(delta_mtyl.logFC <= -(fcthr),delta_mtyl.p_value < pvthr)])]\n",
    "    \n",
    "    return hyper, hypo\n",
    "\n",
    "    \n",
    "def write_gene_file(df,file_name):\n",
    "    \n",
    "    df = pd.DataFrame({'ensembl':[ens[:-3] for ens in df.ensembl.tolist()]}).drop_duplicates('ensembl')\n",
    "    df.to_csv(file_name,sep='\\t',index=None,header=None)\n",
    "    \n",
    "\n",
    "hyper, hypo = two_sided_mtyl()\n",
    "write_gene_file(hyper,'combined_analysis/hyper_mtyl.txt')\n",
    "write_gene_file(hypo,'combined_analysis/hypo_mtyl.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p combined_analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using a [TEISER](https://github.com/goodarzilab/TEISER) script to do enrichment test \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "declare -a Genesets=('hyper_mtyl' 'hypo_mtyl')\n",
    "declare -a Experiments=(\n",
    "# Ribo-seq\n",
    "'Ribo-seq/hl60_delta_te.txt'\n",
    "\n",
    "## HL-60 RNA-seq \n",
    "# RNA experssion \n",
    "'RNA-seq/hl60-exp/6h_delta_exp.txt' 'RNA-seq/hl60-exp/72h_delta_exp.txt' 'RNA-seq/hl60-exp/120h_delta_exp.txt' \n",
    "# RNA stability  \n",
    "'RNA-seq/hl60-stbl/120h_delta_stbl.txt'  'RNA-seq/hl60-stbl/6h_delta_stbl.txt'\n",
    "\n",
    "## 5 other AML cell lines RNA-seq\n",
    "# RNA experssion \n",
    "'RNA-seq/other-exp/kg1_delta_exp.txt' 'RNA-seq/other-exp/molm14_delta_exp.txt'\n",
    "'RNA-seq/other-exp/ociaml2_delta_exp.txt' 'RNA-seq/other-exp/ociaml3_delta_exp.txt'\n",
    "'RNA-seq/other-exp/thp1_delta_exp.txt'\n",
    "# RNA stability  \n",
    "'RNA-seq/other-stbl/kg1_delta_stbl.txt' 'RNA-seq/other-stbl/molm14_delta_stbl.txt' \n",
    "'RNA-seq/other-stbl/ociaml2_delta_stbl.txt' 'RNA-seq/other-stbl/ociaml3_delta_stbl.txt'\n",
    "'RNA-seq/other-stbl/thp1_delta_stbl.txt'\n",
    ")\n",
    "\n",
    "for exp in \"${Experiments[@]}\"; do\n",
    "    for geneset in \"${Genesets[@]}\"; do\n",
    "    \n",
    "#         echo $exp $geneset\n",
    "        base=`basename $exp`\n",
    "        base=${base/.txt/}\n",
    "        \n",
    "        # get intersect \n",
    "        awk 'NR==FNR{A[$1];next}$1 in A' $exp combined_analysis/${geneset}.txt > combined_analysis/${geneset}_${base}.txt\n",
    "        \n",
    "        perl $TEISERDIR/run_mi_gene_list.pl \\\n",
    "            --expfile=$exp \\\n",
    "            --genefile=combined_analysis/${geneset}_${base}.txt \\\n",
    "            --exptype=continuous \\\n",
    "            --ebins=7 \\\n",
    "            --species=human \\\n",
    "            --doremovedups=0 \\\n",
    "            --doremoveextra=0 &> combined_analysis/${geneset}_${base}.log\n",
    "        # remove results from previous run \n",
    "        rm -fr combined_analysis/${geneset}_${base}_GENESET\n",
    "        \n",
    "        rm combined_analysis/${geneset}_${base}.txt\n",
    "        mv ${exp}_GENESET combined_analysis/${geneset}_${base}_GENESET\n",
    "        \n",
    "#         echo 'done!'\n",
    "        \n",
    "    done \n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Redraw heatmaps using `--min=-3 --max=3` thresholds for those plots which have smaller range of signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "declare -a Genesets=('hyper_mtyl' 'hypo_mtyl')\n",
    "declare -a Experiments=(\n",
    "'6h_delta_stbl' '120h_delta_stbl' \n",
    "'kg1_delta_stbl' 'ociaml2_delta_stbl' 'molm14_delta_stbl' \n",
    "'ociaml3_delta_stbl' 'thp1_delta_stbl'\n",
    "'hl60_delta_te'\n",
    ")\n",
    "for exp in \"${Experiments[@]}\"; do\n",
    "    for geneset in \"${Genesets[@]}\"; do\n",
    "#         echo $exp $geneset    \n",
    "        perl $TEISERDIR/Scripts/teiser_draw_matrix.pl \\\n",
    "        --pvmatrixfile=combined_analysis/${geneset}_${exp}_GENESET/${exp}.txt.matrix \\\n",
    "        --summaryfile=combined_analysis/${geneset}_${exp}_GENESET/${exp}.txt.summary \\\n",
    "        --expfile=combined_analysis/${geneset}_${exp}_GENESET/${exp}.txt \\\n",
    "        --quantized=0 \\\n",
    "        --colmap=$TEISERDIR/Scripts/HEATMAPS/cmap_1.txt \\\n",
    "        --order=0 \\\n",
    "        --min=-3 --max=3 \\\n",
    "        --cluster=5 &>> combined_analysis/${geneset}_${exp}.log\n",
    "        \n",
    "#         echo 'done!'\n",
    "        \n",
    "    done \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Make `png` figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p combined_analysis/plots/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "for pdf in combined_analysis/*_GENESET/*.txt.summary.pdf; do \n",
    "    png=${pdf/.pdf/.png}\n",
    "    di=`dirname $pdf`\n",
    "    out=`basename $di`\n",
    "    outpng=${out/_GENESET/.png}\n",
    "    outpdf=${out/_GENESET/.pdf}\n",
    "    \n",
    "    bash /rumi/shams/abe/GitHub/Abe/my_scripts/pdf2png.sh $pdf\n",
    "    cp $pdf combined_analysis/plots/$outpdf\n",
    "    mv $png combined_analysis/plots/$outpng\n",
    "done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write README.md draft\n",
    "    - Write HTML codes which link all plots into a `README.md` format to prepare GitHub friendly report"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash \n",
    "touch combined_analysis/README.md\n",
    "for f in combined_analysis/*.png; do \n",
    "    b=`basename $f`\n",
    "    t=${b/.png/}\n",
    "    echo '#### '$t >> combined_analysis/README.md\n",
    "    echo -e \"<img src=\\\"\"$f\"\\\" title=\\\"\"$t\"\\\" style=\\\"width:1000px\\\">\\n\" >> combined_analysis/README.md\n",
    "done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-geometric test\n",
    "\n",
    "### Goal\n",
    "Here, I aim to take iPAGE results ran on CRISPR screening scores to test hyper/hypo methylation enrichment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "- Clean up iPAGE results with no signal"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash \n",
    "for pv in `ls screen/CRISPRi_HL60_rho/*/pvmatrix.*.txt`; do \n",
    "    b=`basename $pv`; b=${b/pvmatrix./};b=${b/.txt/}\n",
    "    if  [ \"$(wc -l < $pv)\" -eq \"$(echo '1')\" ]; then \n",
    "        echo `dirname $pv` $b NO SIGNAL!\n",
    "        rm -v $pv\n",
    "    elif [ \"$(wc -l < $pv)\" -eq \"$(echo '0')\" ]; then \n",
    "        echo `dirname $pv` $b NO DATA!\n",
    "        rm -v $pv\n",
    "    else\n",
    "        echo `dirname $pv` $b `cat $pv | wc -l`\n",
    "    fi\n",
    "    echo '------------'\n",
    "done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read iPAGE results into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://bioinformatics.stackexchange.com/questions/5400/how-to-convert-data-in-gmt-format-to-dataframe\n",
    "# https://gseapy.readthedocs.io/en/latest/gseapy_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gmt(PATH):\n",
    "    with open(PATH) as gmt:\n",
    "        lines = gmt.readlines()\n",
    "        out = {}\n",
    "        for line in lines:\n",
    "            data = line.split('\\t')\n",
    "            name = data[0]\n",
    "            url  = data[1]\n",
    "            genes= data[2:]\n",
    "            genes[-1] = genes[-1].split('\\n')[0]\n",
    "\n",
    "            out[name] = {}\n",
    "            out[name]['url'] = url \n",
    "            out[name]['genes'] = genes\n",
    "            \n",
    "    return out\n",
    "\n",
    "\n",
    "def read_page_index(PATH):\n",
    "    with open(PATH) as raw:\n",
    "        lines = raw.readlines()\n",
    "        out = {}\n",
    "        for line in lines:\n",
    "            data = line.split('\\t')\n",
    "            gene = data[0]\n",
    "            pathways  = data[1:]\n",
    "            pathways[-1] = pathways[-1].split('\\n')[0]\n",
    "\n",
    "            out[gene] = {}\n",
    "            out[gene]['pathways'] = pathways\n",
    "    return out\n",
    "\n",
    "\n",
    "def read_page_names(PATH):\n",
    "    with open(PATH) as raw:\n",
    "        lines = raw.readlines()\n",
    "        out = {}\n",
    "    for line in lines:\n",
    "            data = line.split('\\t')\n",
    "            name0= data[0]\n",
    "            name1= data[1]\n",
    "            pw_type= data[2].split('\\n')[0]\n",
    "            out[name0] = [name1, pw_type]\n",
    "    return out\n",
    "\n",
    "\n",
    "def read_page_annotations(gs_name,ANNDIR='/flash/bin/iPAGEv1.0/PAGE_DATA/ANNOTATIONS/'):\n",
    "    '''\n",
    "    Read gene set annotations into python from PAGE_DATA format\n",
    "    '''\n",
    "    index = read_page_index(glob(ANNDIR+gs_name+'/*_index.txt')[0] )\n",
    "    names = read_page_names(glob(ANNDIR+gs_name+'/*_names.txt')[0] )\n",
    "    gmt = glob(ANNDIR+gs_name+'/*.gmt')\n",
    "    \n",
    "    annotations = {}\n",
    "    annotations['index'] = index\n",
    "    annotations['names'] = names\n",
    "    if gmt:\n",
    "        annotations['gmt'] = read_gmt(gmt[0])\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "\n",
    "def make_page_dict(PATH):\n",
    "    '''\n",
    "    PATH = a complete path to a pvmatrix.txt file, part of results from iPAGE run \n",
    "    Processes: \n",
    "    1) Read p-value matrix data into a data frame\n",
    "    2) Include annotations for the gene set from the PAGE directory\n",
    "    Output: Python dictionary contain pvmatrix and related annotations to the gene set\n",
    "    '''\n",
    "    ### 1 ### \n",
    "    # read pvmatrix.txt file \n",
    "    df = pd.read_csv(PATH, sep='\\t',index_col=0)\n",
    "    # remove duplicated named (row) names \n",
    "    if all([geneset.split(' ')[0] == geneset.split(' ')[1] for geneset in df.index.tolist()]):\n",
    "        df.index = [geneset.split(' ')[0] for geneset in df.index.tolist() ]\n",
    "        \n",
    "    ### 2 ### \n",
    "    gs_name = PATH.split('/')[-2]\n",
    "    ann = read_page_annotations(gs_name)\n",
    "\n",
    "    out = {}\n",
    "    out['gs_name'] = gs_name\n",
    "    out['annotations'] = ann\n",
    "    out['data'] = df\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_page = [make_page_dict(path) for path in glob('screen/CRISPRi_HL60_rho/*/pvmatrix.L.txt')]\n",
    "r_page = [make_page_dict(path) for path in glob('screen/CRISPRi_HL60_rho/*/pvmatrix.R.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run the hypergeom test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/JohnDeJesus22/DataScienceMathFunctions/blob/master/hypergeometricfunctions.py#L38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import comb\n",
    "\n",
    "def hypergeom_pmf(N, A, n, x):\n",
    "    \n",
    "    '''\n",
    "    Probability Mass Function for Hypergeometric Distribution\n",
    "    :param N: population size\n",
    "    :param A: total number of desired items in N\n",
    "    :param n: number of draws made from N\n",
    "    :param x: number of desired items in our draw of n items\n",
    "    :returns: PMF computed at x\n",
    "    '''\n",
    "    Achoosex = comb(A,x)\n",
    "    NAchoosenx = comb(N-A, n-x)\n",
    "    Nchoosen = comb(N,n)\n",
    "    \n",
    "    return (Achoosex)*NAchoosenx/Nchoosen\n",
    "    \n",
    "    \n",
    "def hypergeom_cdf(N, A, n, t, min_value=None):\n",
    "    \n",
    "    '''\n",
    "    Cumulative Density Funtion for Hypergeometric Distribution\n",
    "    :param N: population size\n",
    "    :param A: total number of desired items in N\n",
    "    :param n: number of draws made from N\n",
    "    :param t: number of desired items in our draw of n items up to t\n",
    "    :returns: CDF computed up to t\n",
    "    '''\n",
    "    if min_value:\n",
    "        return np.sum([hypergeom_pmf(N, A, n, x) for x in range(min_value, t+1)])\n",
    "    \n",
    "    return np.sum([hypergeom_pmf(N, A, n, x) for x in range(t+1)])\n",
    "\n",
    "\n",
    "def hypergeom_plot(N, A, n):\n",
    "    \n",
    "    '''\n",
    "    Visualization of Hypergeometric Distribution for given parameters\n",
    "    :param N: population size\n",
    "    :param A: total number of desired items in N\n",
    "    :param n: number of draws made from N\n",
    "    :returns: Plot of Hypergeometric Distribution for given parameters\n",
    "    '''\n",
    "    \n",
    "    x = np.arange(0, n+1)\n",
    "    y = [hypergeom_pmf(N, A, n, x) for x in range(n+1)]\n",
    "    plt.plot(x, y, 'bo')\n",
    "    plt.vlines(x, 0, y, lw=2)\n",
    "    plt.xlabel('# of desired items in our draw')\n",
    "    plt.ylabel('Probablities')\n",
    "    plt.title('Hypergeometric Distribution Plot')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyper, hypo = [set(list(mtyl.name)) for mtyl in two_sided_mtyl()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmt = l_page[3]['annotations']['gmt']\n",
    "pw = [gmt[pw]['genes'] for pw in gmt][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(hyper)\n",
    "A = len(intersection(hyper, pw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function hypergeom_cdf in module __main__:\n",
      "\n",
      "hypergeom_cdf(N, A, n, t, min_value=None)\n",
      "    Cumulative Density Funtion for Hypergeometric Distribution\n",
      "    :param N: population size\n",
      "    :param A: total number of desired items in N\n",
      "    :param n: number of draws made from N\n",
      "    :param t: number of desired items in our draw of n items up to t\n",
      "    :returns: CDF computed up to t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hypergeom_cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.206289814275411e-07"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypergeom_cdf(N,A,5,4, min_value=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! I need to write something that can read index and names in iPAGE format, easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deseq]",
   "language": "python",
   "name": "conda-env-deseq-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
