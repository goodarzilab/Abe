{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This notebook is a summery of preprocessing and exploratory data analysis of two set of meRIP-Seq data from patient with COVID19. For each patient, we have sequence results for both input/IP for each sample. Here we use `exomePeak` for peak calling. To our experience, this is the only package comparing to other methods that supports samples from one conditions for the peak calling task; where other methods (like `RADAR`) require samples from two conditions to do both peak calling and differential analysis which is not our interest here.\n",
    "\n",
    "Totally, there are 44 sequencing samples, 22 patients with both IN and RIP. \n",
    "\n",
    "Current pipeline contain these steps: \n",
    "\n",
    "#### Human genome \n",
    "0. Run `bcl2fastq` to make fastq files from raw data\n",
    "        - input: bcl\n",
    "        - output: fastq\n",
    "1. Using `cutadapt` to trim few bps from the sequencing library.\n",
    "        - input: fastq\n",
    "        - output: fastq\n",
    "2. Align to human genome using `STAR` and write unaligned reads in seprate `fastq` files\n",
    "        - input: fastq\n",
    "        - output1: bam\n",
    "        - output2: fastq\n",
    "3. Call human m6A peaks in each samples using `exomePeak` (see [here](https://bioconductor.riken.jp/packages/3.0/bioc/html/exomePeak.html)) and `gencode.v28.annotation`. \n",
    "        - input1: gtf\n",
    "        - input2: bam\n",
    "        - output: bed12\n",
    "\n",
    "4. Taking bed12 results from step 3:\n",
    "    1. Drawing meta-gene plot using `Guitar` (see [here](https://bioconductor.org/packages/3.11/bioc/html/Guitar.html)). \n",
    "    2. Using `cgat` (see [here](https://cgat.readthedocs.io/en/latest/cgat.html)) to prepare FIRE input. \n",
    "    2. Motif analysis using `FIRE`\n",
    "    \n",
    "Final results reported separately [here](https://github.com/goodarzilab/Abe/blob/master/Projects/COVID19_m6A/human-report.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Virus genome \n",
    "5. Using `STAR` to build index and map COVID19 genome to unaligned reads to the human genome.\n",
    "    According to Matt's epxeriance ([link](https://github.com/goodarzilab/khorms/blob/master/side_projects/COVID_DMSseq_library.ipynb)), I'm using [this genome annotation](https://www.ncbi.nlm.nih.gov/nuccore/MN908947?%3Fdb=nucleotide). \n",
    "        - input: fastq\n",
    "            output2 of step 2. \n",
    "        - output: bam \n",
    "\n",
    "\n",
    "6. Using `exomePeak` with custom option that make it work for calling virus peaks. \n",
    "        - input1: gtf\n",
    "        - input2: bam\n",
    "        - output: bed12\n",
    "\n",
    "7. Albertas is using m6A+ m6A- internal controls from [N6-Methyladenosine Enrichment Kit](https://international.neb.com/-/media/nebus/files/manuals/manuale1610.pdf?rev=c064d5e232414f709ef8bccee56f7687&hash=AAA94B8FDA043DD5A610E14686552B5E0209EA94). I'm using `bowtie2` to align reads in the `output2` from step 2. In a scatter plot, qPCR Ct for each patients is compered with number of virus m6A peaks.\n",
    "\n",
    "\n",
    "8. Merge and intersect peaks found in all samples into a single `bed6` file and extract peak sequences. \n",
    "        - inputs: bed12\n",
    "            outputs of step 6\n",
    "        - output1: bed\n",
    "        - output2: fasta\n",
    "\n",
    "9. Count virus peaks as features using `bamToBed` plus `intersectBed` to count reads that aligned to each peaks. \n",
    "        - input1: bam \n",
    "            output of step 5.\n",
    "        - input2: bed\n",
    "            output1 of step 8. \n",
    "        - output: count-matrix \n",
    "\n",
    "        \n",
    "10. Motif analysis using `regex` by extracting the sequence of each peaks and quary patterns\n",
    "        - input: fasta\n",
    "            output2 of step 8. \n",
    "        - output: motif-dataframe\n",
    "\n",
    "\n",
    "12. Implement R code from [here](https://github.com/lzcyzm/exomePeak/blob/master/R/ctest.R) to run `ctest` which evaluate m6A vs. input foldchange, pvalue and fdr for every peaks in all 22 samples. \n",
    "\n",
    "\n",
    "11. Also, there are WGS `fasta` results for several samples. For mutation analysis, I'm applying fuzzy string matching which calculate **Levenshtein Distance** between each peak sequence within the sample sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.10 | packaged by conda-forge | (default, Apr 24 2020, 16:44:11) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os \n",
    "import sys \n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from fuzzywuzzy import fuzz\n",
    "from scipy import stats \n",
    "from matplotlib.patches import Rectangle\n",
    "import sklearn.preprocessing as pp\n",
    "import rpy2.robjects as ob\n",
    "\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Samples = [\n",
    "    \"S0008\",\"S0009\",\"S0014\",\"S0017\",\"S0025\",\n",
    "    \"S0026\",\"S0030\",\"S0042\",\"S0057\",\"S0085\",\n",
    "    \"COV00075\",\"COV00079\",\"COV00084\",\"COV00087\",\"COV00093\",\"COV00106\",\n",
    "    \"COV00397\",\"COV00413\",\"COV00417\",\"COV00419\",\"COV00422\",\"COV00432\"    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "renameSamples = [S.replace('S', 'COV0') for S in Samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Some of below scripts repeated for both set of samples separately)\n",
    "\n",
    "(I have used several separate conda environments for this analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. `bcl2fastq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd ~/Projects/COVID19_m6A/second_dataset\r\n",
      "\r\n",
      "mkdir -p fastq/\r\n",
      "mkdir -p _sh/\r\n",
      "mkdir -p _sh/bcl2fastq/\r\n",
      "\r\n",
      "bcl2fastq --create-fastq-for-index-reads \\\r\n",
      "--runfolder-dir 200527_NS500257_0113_AH2VKLBGXF \\\r\n",
      "-r 18 -p 18 \\\r\n",
      "-o fastq/ \\\r\n",
      "--sample-sheet 200527_NS500257_0113_AH2VKLBGXF/200527_meRIPseq.csv \\\r\n",
      "--no-lane-splitting \\\r\n",
      "--stats-dir _sh/bcl2fastq/ \\\r\n",
      "--reports-dir _sh/bcl2fastq/\r\n"
     ]
    }
   ],
   "source": [
    "cat second_dataset/_sh/bcl2fastq.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Trimming task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the first three nucleotides of the second reads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir -p trim\r\n",
      "for fq in fastq/S00*R2*; do\r\n",
      "\tfq=`basename $fq`;\r\n",
      "\tout=${fq/_001.fastq.gz/.trim.fastq.gz};\r\n",
      "\techo -------------------------$fq------------------------\r\n",
      "\tcutadapt -j 12 -u 3 -o trim/$out fastq/$fq\r\n",
      "done\r\n"
     ]
    }
   ],
   "source": [
    "cat second_dataset/_sh/trim.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Alignment task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd ~/Projects/COVID19_m6A/second_dataset\r\n",
      "mkdir -p bam\r\n",
      "\r\n",
      "STAR --genomeLoad LoadAndExit --genomeDir /rumi/shams/genomes/hg38/\r\n",
      "for fq in fastq/*R1*; do\r\n",
      "    fq1=`basename $fq`\r\n",
      "    fq2=${fq1/_R1_/_R2_}\r\n",
      "    fq2=${fq2/.fastq.gz/.trim.fastq.gz}\r\n",
      "    out=${fq1/_R1_001.fastq.gz/}\r\n",
      "    STAR \\\r\n",
      "    --outSAMtype BAM SortedByCoordinate \\\r\n",
      "    --readFilesCommand zcat \\\r\n",
      "    --runThreadN 16 \\\r\n",
      "    --genomeDir /rumi/shams/genomes/hg38/ \\\r\n",
      "    --readFilesIn fastq/$fq1 trim/$fq2 \\\r\n",
      "    --outFileNamePrefix bam/$out \\\r\n",
      "    --outReadsUnmapped Fastx; \r\n",
      "done\r\n",
      "STAR --genomeLoad Remove --genomeDir /rumi/shams/genomes/hg38/\r\n"
     ]
    }
   ],
   "source": [
    "cat second_dataset/_sh/star.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Human peak calling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIN=/rumi/shams/abe/Projects/COVID19_m6A/second_dataset\r\n",
      "PEAKS=exomepeak/human\r\n",
      "\r\n",
      "cd $MAIN\r\n",
      "for f in bam/*_IN*.bam; do \r\n",
      "\tb=`basename $f`; \r\n",
      "\tb=${b/_IN.bam/}; \r\n",
      "\techo -------------------------$b------------------------\r\n",
      "        Rscript _sh/exompeak.R $MAIN $PEAKS $b _IN _RIP\r\n",
      "\techo 'All done!'\r\n",
      "done\r\n"
     ]
    }
   ],
   "source": [
    "cat second_dataset/_sh/peak.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "library(GenomicFeatures)\r\n",
      "library(exomePeak)\r\n",
      "\r\n",
      "args <- commandArgs(trailingOnly = TRUE)\r\n",
      "\r\n",
      "jobID  <- args[1]\r\n",
      "OUTPUT <- args[2]\r\n",
      "Sample <- args[3]\r\n",
      "INPUT <- args[4]\r\n",
      "IP <- args[5]\r\n",
      "\r\n",
      "######################################## read meta ######################################$\r\n",
      "\r\n",
      "IP_BAM = paste(Sample, IP, '.bam', sep='')\r\n",
      "INPUT_BAM = paste(Sample, INPUT, '.bam', sep='')\r\n",
      "\r\n",
      "print (IP_BAM)\r\n",
      "print (INPUT_BAM)\r\n",
      "\r\n",
      "######################################## functions ######################################\r\n",
      "GTF = '/rumi/shams/genomes/hg38/gencode.v28.annotation.gtf'\r\n",
      "organism= 'Homo sapiens'\r\n",
      "\r\n",
      "txdb <- makeTxDbFromGFF(GTF, organism=organism )\r\n",
      "\r\n",
      "setwd(jobID)\r\n",
      "setwd(\"./bam\")\r\n",
      "\r\n",
      "print (txdb)\r\n",
      "\r\n",
      "res <- exomepeak(\r\n",
      "\tTXDB=txdb,\r\n",
      "\tIP_BAM=IP_BAM,\r\n",
      "\tINPUT_BAM=INPUT_BAM,\r\n",
      "\tOUTPUT_DIR=paste('..',OUTPUT,sep='/'),\r\n",
      "\tEXPERIMENT_NAME=Sample\r\n",
      ")\r\n",
      "saveRDS(res, paste('..', OUTPUT, Sample, 'results.rds', sep='/'))\r\n"
     ]
    }
   ],
   "source": [
    "cat second_dataset/_sh/exompeak.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Downstream analysis of human data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I run `Guitar.R` to generate meta-gene plots and `motif.sh` for motif analysis of `DRACH` and `RGAC` motifs and also motif analysis in discovery mode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw meta-gene plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for f in bam/*_IN*.bam; do\r\n",
      "\tb=`basename $f`;\r\n",
      "\tb=${b/_IN.bam/};\r\n",
      "\techo -------------------------$b------------------------;\r\n",
      "\tRscript _sh/guitar.R exomepeak/human/$b peak.bed $b;\r\n",
      "done\r\n"
     ]
    }
   ],
   "source": [
    "cat second_dataset/_sh/guitar.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "library(Guitar)\r\n",
      "\r\n",
      "args <- commandArgs(trailingOnly = TRUE)\r\n",
      "\r\n",
      "jobID <- args[1]\r\n",
      "bed_file <- args[2]\r\n",
      "plot_prefix <- args[3]\r\n",
      "\r\n",
      "setwd(jobID)\r\n",
      "list.files()\r\n",
      "print (bed_file)\r\n",
      "\r\n",
      "txdb <- makeTxDbFromGFF('/rumi/shams/genomes/hg38/gencode.v28.annotation.gtf',organism='Homo sapiens')\r\n",
      "\r\n",
      "GuitarPlot(txTxdb=txdb,stBedFiles=list(bed_file),miscOutFilePrefix=plot_prefix)\r\n"
     ]
    }
   ],
   "source": [
    "cat second_dataset/_sh/guitar.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motif analysis \n",
    "Prepare inputs and run [FIRE](https://github.com/goodarzilab/FIRE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIN=/rumi/shams/abe/Projects/COVID19_m6A/second_dataset\r\n",
      "PEAKS=exomepeak/human\r\n",
      "MOTIF=/rumi/shams/abe/Projects/COVID19_m6A/motifs.txt\r\n",
      "\r\n",
      "cd ${MAIN}/${PEAKS}\r\n",
      "for sam in *; do\r\n",
      "\tcd $sam\r\n",
      "\t# step 1: extract mRNA sequences\r\n",
      "\tcat peak.bed | sort -k1,1 -k2,2n peak.bed | cgat bed2bed --method=merge --merge-by-name |  awk '! /#/' | bedtools getfasta -name -s -fi /rumi/shams/genomes/hg38/hg38.fa -bed - -split -fo peak.fa\r\n",
      "        # step 2: prepare inputs for FIRE\r\n",
      "\tperl $TEISERDIR/prep_seqs_for_teiser_run.pl peak.fa peaks\r\n",
      "\t# step 3: run FIRE for known m6A motifs (non-discovery mode)\r\n",
      "\tperl $FIREDIR/fire.pl --expfile=peaks_teiser.txt --exptype=discrete --fastafile_rna=peaks_teiser.fa \\\r\n",
      "\t--nodups=1 --dodna=0 --dodnarna=0 --species=human --doskipdiscovery=1 --motiffile_rna=$MOTIF --oribiasonly=0\r\n",
      "\tmv -v peaks_teiser.txt_FIRE/ non-discovery_FIRE\r\n",
      "\t# step 4: run FIRE discovery mode\r\n",
      "\tperl $FIREDIR/fire.pl --expfile=peaks_teiser.txt --exptype=discrete --fastafile_rna=peaks_teiser.fa \\\r\n",
      "\t--nodups=1 --dodna=0 --dodnarna=0 --species=human --oribiasonly=0\r\n",
      "        mv -v peaks_teiser.txt_FIRE/ discovery_FIRE\r\n",
      "\tcd ../\r\n",
      "done\r\n"
     ]
    }
   ],
   "source": [
    "cat second_dataset/_sh/motif.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virus genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Alignment task for COVID19 genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# map to virus genome \r\n",
      "# https://www.ncbi.nlm.nih.gov/nuccore/MN908947?%3Fdb=nucleotide\r\n",
      "# STAR --runThreadN 16 \\\r\n",
      "# --runMode genomeGenerate \\\r\n",
      "# --genomeDir ../virus/ \\\r\n",
      "# --genomeFastaFiles ../virus/coronavirus_2_isolate_Wuhan-Hu-1.fasta \\\r\n",
      "# --sjdbGTFfile ../virus/coronavirus_2_isolate_Wuhan-Hu-1.gff3 \\\r\n",
      "# --sjdbOverhang 99 --genomeSAindexNbases 8 --sjdbGTFfeatureExon CDS\r\n",
      "\r\n",
      "mkdir -p virus_bam\r\n",
      "STAR --genomeLoad LoadAndExit --genomeDir ../virus/\r\n",
      "\r\n",
      "for fq in virus_fastq/*mate1; do\r\n",
      "\tfq1=`basename $fq`;\r\n",
      "\tfq2=${fq1/mate1/mate2};\r\n",
      "\tout=${fq1/_Unmapped.out.mate1/};\r\n",
      "\techo 'sample ' $fq1\r\n",
      "\tSTAR \\\r\n",
      "\t--outSAMtype BAM SortedByCoordinate \\\r\n",
      "\t--readFilesCommand cat \\\r\n",
      "\t--runThreadN 16 \\\r\n",
      "\t--genomeDir ../virus/ \\\r\n",
      "\t--readFilesIn virus_fastq/$fq1 virus_fastq/$fq2 \\\r\n",
      "\t--outFileNamePrefix virus_bam/$out \\\r\n",
      "\t--limitBAMsortRAM 1000000000;\r\n",
      "done\r\n",
      "STAR --genomeLoad Remove --genomeDir ../virus/\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "cat second_dataset/_sh/virus_star.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Virus peak calling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've played with `exomePeak` thresholds and we ended up using  ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIN=/rumi/shams/abe/Projects/COVID19_m6A/\r\n",
      "PEAKS=exomepeak/virus\r\n",
      "\r\n",
      "cd $MAIN\r\n",
      "\r\n",
      "for f in */bam/*_IN*.bam; do\r\n",
      "\tb=`basename $f`;\r\n",
      "\tb=${b/_IN.bam/};\r\n",
      "\techo -------------------------$b------------------------\r\n",
      "        Rscript _sh/exompeak.virus.R $MAIN $PEAKS $b _IN _RIP 0.025\r\n",
      "\techo 'All done!'\r\n",
      "done\r\n"
     ]
    }
   ],
   "source": [
    "cat _sh/virus_peak.sh  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args <- commandArgs(trailingOnly = TRUE)\r\n",
      "\r\n",
      "print(args)\r\n",
      "jobID  <- args[1]\r\n",
      "OUTPUT <- args[2]\r\n",
      "Sample <- args[3]\r\n",
      "INPUT <- args[4]\r\n",
      "IP <- args[5]\r\n",
      "FDR <- args[6]\r\n",
      "\r\n",
      "library(GenomicFeatures)\r\n",
      "library(exomePeak)\r\n",
      "\r\n",
      "GTF = '~/Projects/COVID19_m6A/virus/coronavirus_2_isolate_Wuhan-Hu-1.gff3'\r\n",
      "######################################## read meta ######################################$\r\n",
      "IP_BAM = paste(Sample, IP, '.bam', sep='')\r\n",
      "INPUT_BAM = paste(Sample, INPUT, '.bam', sep='')\r\n",
      "\r\n",
      "######################################## functions ######################################\r\n",
      "txdb <- makeTxDbFromGFF(GTF, organism=NA )\r\n",
      "\r\n",
      "setwd(jobID)\r\n",
      "setwd(\"./virus_bam\")\r\n",
      "\r\n",
      "WINDOW = 50\r\n",
      "STEP = 10\r\n",
      "LENGTH = 200\r\n",
      "ENRICH = 1\r\n",
      "EXP = paste(Sample,'FDR', FDR,sep='_')\r\n",
      "\r\n",
      "options(digits=5)\r\n",
      "res <- exomepeak(\r\n",
      "        TXDB = txdb,\r\n",
      "        IP_BAM=IP_BAM,\r\n",
      "        INPUT_BAM=INPUT_BAM,\r\n",
      "        OUTPUT_DIR=paste('..',OUTPUT,sep='/'),\r\n",
      "        EXPERIMENT_NAME=EXP,\r\n",
      "        # options\r\n",
      "        WINDOW_WIDTH = WINDOW,\r\n",
      "        SLIDING_STEP = STEP,\r\n",
      "        FRAGMENT_LENGTH = LENGTH,\r\n",
      "        PEAK_CUTOFF_FDR = as.double(FDR),\r\n",
      "\tPEAK_CUTOFF_PVALUE = 1, \r\n",
      "\tFOLD_ENRICHMENT = ENRICH\r\n",
      ")\r\n",
      "\r\n",
      "saveRDS(res, paste('..', OUTPUT, EXP, 'results.rds', sep='/'))\r\n"
     ]
    }
   ],
   "source": [
    "cat _sh/exompeak.virus.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. internal control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I copied the actual sequence for both _m6A+_ and _m6A-_ control fragments from the documentation of [N6-Methyladenosine Enrichment Kit](https://international.neb.com/-/media/nebus/files/manuals/manuale1610.pdf?rev=c064d5e232414f709ef8bccee56f7687&hash=AAA94B8FDA043DD5A610E14686552B5E0209EA94). Then, I manually made `bed` file and `fasta` file for each of these two sequences. Finally, I use `bowtie2` to map them to the `fastq` files which generated from reads that doesn't map to the human genome. \n",
    "\n",
    "Here, for a quality control of the samples, we are comparing:\n",
    "$$\\log_2\\dfrac{RIP}{IN}$$\n",
    "for both _m6A+_ and _m6A-_ controls with qPCR Ct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the sequences and `bed` files folowing with bash scripts I've used for alignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">m6A Control RNA (Cypridina Luciferase): 1706 nt\r\n",
      "GGAGACCCAAGCTTGGTACCGAGCTCGGATCCGCCACCATGAAGACCTTAATTCTTGCCGTTGCATTAGT\r\n",
      "CTACTGCGCCACTGTTCATTGCCAGGACTGTCCTTACGAACCTGATCCACCAAACACAGTTCCAACTTCC\r\n",
      "TGTGAAGCTAAAGAAGGAGAATGTATTGATAGCAGCTGTGGCACCTGCACGAGAGACATACTATCAGATG\r\n",
      "GACTGTGTGAAAATAAACCAGGAAAAACATGTTGCCGAATGTGTCAGTATGTAATTGAATGCAGAGTAGA\r\n",
      "GGCCGCAGGATGGTTTAGAACATTCTATGGAAAGAGATTCCAGTTCCAGGAACCTGGTACATACGTGTTG\r\n",
      "GGTCAAGGAACCAAGGGCGGCGACTGGAAGGTGTCCATCACCCTGGAGAACCTGGATGGAACCAAGGGGG\r\n",
      "CTGTGCTGACCAAGACAAGACTGGAAGTGGCTGGAGACATCATTGACATCGCTCAAGCTACTGAGAATCC\r\n",
      "CATCACTGTAAACGGTGGAGCTGACCCTATCATCGCCAACCCGTACACCATCGGCGAGGTCACCATCGCT\r\n",
      "GTTGTTGAGATGCCAGGCTTCAACATCACCGTCATTGAGTTCTTCAAACTGATCGTGATCGACATCCTCG\r\n",
      "GAGGAAGATCTGTAAGAATCGCCCCAGACACAGCAAACAAAGGAATGATCTCTGGCCTCTGTGGAGATCT\r\n",
      "TAAAATGATGGAAGATACAGACTTCACTTCAGATCCAGAACAACTCGCTAATCAGCCTAAGATCAACCAG\r\n",
      "GAGTTTGACGGTTGTCCACTCTATGGAAATCCTGATGACGTTGCATACTGCAAAGGTCTTCTGGAGCCGT\r\n",
      "ACAAGGACAGCTGCCGCAACCCCATCAACTTCTACTACTACACCATCTCCTGCGCCTTCGCCCGCTGTAT\r\n",
      "GGGTGGAGACGAGCGAGCCTCACACGTGCTGCTTGACTACAGGGAGACGTGCGCTGCTCCCGAAACTAGA\r\n",
      "GGAACCTGCGTTTTGTCTGGACATACTTTCTACGATACATTTGACAAAGCAAGATACCAATTCCAGGGTC\r\n",
      "CCTGCAAGGAGATTCTTATGGCCGCCGACTGTTTCTGGAACACTTGGGATGTGAAGGTTTCACACAGGAA\r\n",
      "TGTTGACTCTTACACTGAAGTAGAGAAAGTACGAATCAGGAAACAATCGACTGTAGTAGAACTCATTGTT\r\n",
      "GATGGAAAACAGATTCTGGTTGGAGGAGAAGCCGTGTCCGTCCCGTACAGCTCTCAGAACACTTCCATCT\r\n",
      "ACTGGCAAGATGGTGACATACTGACTACAGCCATCCTACCTGAAGCTCTGGTGGTCAAGTTCAACTTCAA\r\n",
      "GCAACTGCTCGTCGTACATATTAGAGATCCATTCGATGGTAAGACTTGCGGTATTTGCGGTAACTACAAC\r\n",
      "CAGGATTTCAGTGATGATTCTTTTGATGCTGAAGGAGCCTGTGATCTGACCCCCAACCCACCGGGATGCA\r\n",
      "CCGAAGAACAGAAACCTGAAGCTGAACGACTCTGCAATAGTCTCTTCGCCGGTCAAAGTGATCTTGATCA\r\n",
      "GAAATGTAACGTGTGCCACAAGCCTGACCGTGTCGAACGATGCATGTACGAGTATTGCCTGAGGGGACAA\r\n",
      "CAGGGTTTCTGTGACCACGCATGGGAGTTCAAGAAAGAATGCTACATAAAGCATGGAGACACCCTAGAAG\r\n",
      "TACCAGATGAATGCAAATAGGCGGCC\r\n",
      ">m6A Control RNA (Gaussia Luciferase): 603 nt\r\n",
      "GGAGACCCAAGCTTGGTACCGAGCTCGGATCCAGCCACCATGGGAGTCAAAGTTCTGTTTGCCCTGATCT\r\n",
      "GCATCGCTGTGGCCGAGGCCAAGCCCACCGAGAACAACGAAGACTTCAACATCGTGGCCGTGGCCAGCAA\r\n",
      "CTTCGCGACCACGGATCTCGATGCTGACCGCGGGAAGTTGCCCGGCAAGAAGCTGCCGCTGGAGGTGCTC\r\n",
      "AAAGAGATGGAAGCCAATGCCCGGAAAGCTGGCTGCACCAGGGGCTGTCTGATCTGCCTGTCCCACATCA\r\n",
      "AGTGCACGCCCAAGATGAAGAAGTTCATCCCAGGACGCTGCCACACCTACGAAGGCGACAAAGAGTCCGC\r\n",
      "ACAGGGCGGCATAGGCGAGGCGATCGTCGACATTCCTGAGATTCCTGGGTTCAAGGACTTGGAGCCCATG\r\n",
      "GAGCAGTTCATCGCACAGGTCGATCTGTGTGTGGACTGCACAACTGGCTGCCTCAAAGGGCTTGCCAACG\r\n",
      "TGCAGTGTTCTGACCTGCTCAAGAAGTGGCTGCCGCAACGCTGTGCGACCTTTGCCAGCAAGATCCAGGG\r\n",
      "CCAGGTGGACAAGATCAAGGGGGCCGGTGGTGACTAAGCGGCC\r\n"
     ]
    }
   ],
   "source": [
    "cat int_ctrl/m6A_neg.fa int_ctrl/m6A_pos.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo '-------m6A pos-------'\r\n",
      "bowtie2-build int_ctrl/m6A_pos.fa int_ctrl/m6A_pos\r\n",
      "\r\n",
      "mkdir -p int_ctrl/\r\n",
      "mkdir -p int_ctrl/virus/\r\n",
      "mkdir -p int_ctrl/virus/m6A_pos\r\n",
      "mkdir -p int_ctrl/virus/m6A_neg\r\n",
      "\r\n",
      "\r\n",
      "for f in virus_fastq/*mate1;\r\n",
      "    do f=`basename $f`;\r\n",
      "    f2=${f/mate1/mate2};\r\n",
      "    o=${f/_S*Unmapped.out.mate1/.bam};\r\n",
      "\tbowtie2 -p 12 --sensitive \\\r\n",
      "        -N 1 -x int_ctrl/m6A_pos \\\r\n",
      "        --no-unal \\\r\n",
      "        -1 virus_fastq/$f -2 virus_fastq/$f2 | samtools sort -o int_ctrl/virus/m6A_pos/$o;\r\n",
      "done\r\n",
      "\r\n",
      "echo '-------m6A neg--------'\r\n",
      "bowtie2-build int_ctrl/m6A_neg.fa int_ctrl/m6A_neg\r\n",
      "\r\n",
      "for f in virus_fastq/*mate1;\r\n",
      "    do f=`basename $f`;\r\n",
      "    f2=${f/mate1/mate2};\r\n",
      "    o=${f/_S*Unmapped.out.mate1/.bam};\r\n",
      "\tbowtie2 -p 12 --sensitive \\\r\n",
      "        -N 1 -x int_ctrl/m6A_neg \\\r\n",
      "        --no-unal \\\r\n",
      "        -1 virus_fastq/$f -2 virus_fastq/$f2 | samtools sort -o int_ctrl/virus/m6A_neg/$o;\r\n",
      "done\r\n",
      "\r\n",
      "echo 'All done!'"
     ]
    }
   ],
   "source": [
    "cat second_dataset/_sh/int_ctrl.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmodified\t0\t1706\tneg\t0\t+\r\n",
      "m6A\t0\t603\tpos\t0\t+\r\n"
     ]
    }
   ],
   "source": [
    "cat int_ctrl/m6A_neg.bed int_ctrl/m6A_pos.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! Let's do some `log`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bam2count(bam,bed):\n",
    "    cmd = 'bamToBed -i ' + bam + ' | intersectBed -s -wo -a - -b ' + bed + ' | cut -f10 | sort | uniq -c | awk \\'{print $1}\\''\n",
    "    res = os.popen(cmd).read().split('\\n')[0]\n",
    "    return int(res)\n",
    "\n",
    "def ctrl_count(sample):\n",
    "    # path to ctrl bam files \n",
    "    IN_pos= 'int_ctrl/virus/m6A_pos/' + sample + '_IN.bam'\n",
    "    RIP_pos='int_ctrl/virus/m6A_pos/' + sample + '_RIP.bam'\n",
    "    IN_neg= 'int_ctrl/virus/m6A_neg/' + sample + '_IN.bam'\n",
    "    RIP_neg='int_ctrl/virus/m6A_neg/' + sample + '_RIP.bam'\n",
    "    # bed format \n",
    "    bed_pos = 'int_ctrl/m6A_pos.bed'\n",
    "    bed_neg = 'int_ctrl/m6A_neg.bed'\n",
    "\n",
    "    pos = [bam2count (bam, bed_pos) for bam in [IN_pos, RIP_pos]]\n",
    "    neg = [bam2count (bam, bed_neg) for bam in [IN_neg, RIP_neg]]\n",
    "    results = pos + neg\n",
    "    return results\n",
    "\n",
    "qPCR = pd.read_csv('RTqPCR.txt', sep='\\t',index_col=0)\n",
    "\n",
    "res = pd.DataFrame(\n",
    "    data=[ctrl_count(S) for S in Samples], \n",
    "    index=Samples, columns=['IN_pos', 'RIP_pos', 'IN_neg', 'RIP_neg']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CoV-2 Ct</th>\n",
       "      <th>m6A_pos_ctrl</th>\n",
       "      <th>m6A_neg_ctrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COV00008</th>\n",
       "      <td>19.600</td>\n",
       "      <td>3.683781</td>\n",
       "      <td>-2.090802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00009</th>\n",
       "      <td>18.500</td>\n",
       "      <td>6.804162</td>\n",
       "      <td>-0.219748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00014</th>\n",
       "      <td>16.300</td>\n",
       "      <td>2.141356</td>\n",
       "      <td>-3.560361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00017</th>\n",
       "      <td>24.000</td>\n",
       "      <td>1.651047</td>\n",
       "      <td>-7.253435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00025</th>\n",
       "      <td>22.100</td>\n",
       "      <td>6.203816</td>\n",
       "      <td>-1.010379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00026</th>\n",
       "      <td>15.600</td>\n",
       "      <td>8.585372</td>\n",
       "      <td>2.581687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00030</th>\n",
       "      <td>17.000</td>\n",
       "      <td>8.069236</td>\n",
       "      <td>1.410737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00042</th>\n",
       "      <td>28.000</td>\n",
       "      <td>4.671282</td>\n",
       "      <td>-0.940368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00057</th>\n",
       "      <td>26.700</td>\n",
       "      <td>8.344047</td>\n",
       "      <td>-1.969256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00085</th>\n",
       "      <td>14.600</td>\n",
       "      <td>6.607715</td>\n",
       "      <td>0.843608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00075</th>\n",
       "      <td>12.134</td>\n",
       "      <td>6.235216</td>\n",
       "      <td>-4.446256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00079</th>\n",
       "      <td>12.780</td>\n",
       "      <td>3.930171</td>\n",
       "      <td>-6.468769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00084</th>\n",
       "      <td>14.156</td>\n",
       "      <td>3.927094</td>\n",
       "      <td>-4.303449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00087</th>\n",
       "      <td>14.520</td>\n",
       "      <td>2.938836</td>\n",
       "      <td>-2.161786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00093</th>\n",
       "      <td>14.951</td>\n",
       "      <td>4.353264</td>\n",
       "      <td>-2.033108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00106</th>\n",
       "      <td>14.999</td>\n",
       "      <td>6.303781</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00397</th>\n",
       "      <td>15.489</td>\n",
       "      <td>4.073392</td>\n",
       "      <td>-2.173707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00413</th>\n",
       "      <td>16.050</td>\n",
       "      <td>7.928316</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00417</th>\n",
       "      <td>16.096</td>\n",
       "      <td>5.310316</td>\n",
       "      <td>-2.019194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00419</th>\n",
       "      <td>16.918</td>\n",
       "      <td>4.794616</td>\n",
       "      <td>-3.294183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00422</th>\n",
       "      <td>17.056</td>\n",
       "      <td>6.022368</td>\n",
       "      <td>-0.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COV00432</th>\n",
       "      <td>17.185</td>\n",
       "      <td>7.843398</td>\n",
       "      <td>-0.678072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CoV-2 Ct  m6A_pos_ctrl  m6A_neg_ctrl\n",
       "COV00008    19.600      3.683781     -2.090802\n",
       "COV00009    18.500      6.804162     -0.219748\n",
       "COV00014    16.300      2.141356     -3.560361\n",
       "COV00017    24.000      1.651047     -7.253435\n",
       "COV00025    22.100      6.203816     -1.010379\n",
       "COV00026    15.600      8.585372      2.581687\n",
       "COV00030    17.000      8.069236      1.410737\n",
       "COV00042    28.000      4.671282     -0.940368\n",
       "COV00057    26.700      8.344047     -1.969256\n",
       "COV00085    14.600      6.607715      0.843608\n",
       "COV00075    12.134      6.235216     -4.446256\n",
       "COV00079    12.780      3.930171     -6.468769\n",
       "COV00084    14.156      3.927094     -4.303449\n",
       "COV00087    14.520      2.938836     -2.161786\n",
       "COV00093    14.951      4.353264     -2.033108\n",
       "COV00106    14.999      6.303781     -1.000000\n",
       "COV00397    15.489      4.073392     -2.173707\n",
       "COV00413    16.050      7.928316      0.000000\n",
       "COV00417    16.096      5.310316     -2.019194\n",
       "COV00419    16.918      4.794616     -3.294183\n",
       "COV00422    17.056      6.022368     -0.584963\n",
       "COV00432    17.185      7.843398     -0.678072"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log2(RIP / IN)\n",
    "pos  = np.log2(res['RIP_pos'] / res['IN_pos'])\n",
    "neg  = np.log2(res['RIP_neg'] / res['IN_neg'])\n",
    "\n",
    "qPCR['m6A_pos_ctrl'] = pos \n",
    "qPCR['m6A_neg_ctrl'] = neg \n",
    "samples_with_low_Ct = qPCR[qPCR.iloc[:,0] <= 18].index.tolist()\n",
    "qPCR.index = renameSamples\n",
    "\n",
    "qPCR.to_csv('Results/qPCR_int_ctrl_log2RIPvsIN.txt')\n",
    "qPCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Count peak features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic of this part is: \n",
    "1. Merge `exomepeak` results from all samples\n",
    "2. Take intersect of each samples (`bed12`) \n",
    "3. Write it into fresh `bed6` format\n",
    "4. Rename peaks from one transcript into uniq names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# merge beds from all samples \n",
    "cat exomepeak/virus/*/peak.bed | grep -v '^ *#' | bed12ToBed6 | sort -k1,1 -k2,2n | \\\n",
    "# merge all peaks \n",
    "mergeBed -i - -c 4 -o distinct | \\\n",
    "# get intersects of all samples in the merged bed file\n",
    "bedtools intersect -wo -F 0.85 -a - -b exomepeak/virus/*/peak.bed | \\\n",
    "awk '{print $6\"\\t\"$7\"\\t\"$8\"\\t\"$9\"\\t\"\".\"\"\\t\"$11}' | uniq | \\\n",
    "# rename peaks with unique names \n",
    "awk -F \"\\t\" '{OFS=FS}{$4=$4\"_peak\"}; cnt[$4]++{$4=$4\"_\"cnt[$4]} 1' > merge_peaks.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count peak coverage in each sample (`bam` file) for downstream analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# peak count\n",
    "for f in virus_bam/*bam; do\n",
    "    base=`basename $f`;\n",
    "    out=${base/.bam/.fc};\n",
    "    bamToBed -i $f | intersectBed -split -c -a merge_peaks.bed -b - | \\\n",
    "    awk '{ print $4 \"\\t\" $7}' > virus_count/$out; \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Motif analysis \n",
    "Extract peak sequences and search for `DRACH`, `RGAC`, `AAGAA` motifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# get peak sequences\n",
    "bedtools getfasta -name -s -fi virus/coronavirus_2_isolate_Wuhan-Hu-1.fasta -bed \\\n",
    "merge_peaks.bed -split -fo merge_peaks.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loci</th>\n",
       "      <th>DRACH</th>\n",
       "      <th>RGAC</th>\n",
       "      <th>AAGAA</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S_peak</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>GGACT,GAACC,AGACT,TGACC,AAACA,AAACT,TAACT,AAAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S_peak_3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>GAACT,TGACA,TGACC,AGAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S_peak_4</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>GAACT,TGACA,GGACT,GGACC,TAACC,TAACA,AGACC,AAAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S_peak_5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TAACA,AAACC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S_peak_6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>GAACT,GGACC,AAACA,TAACA,GGAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>N_peak_43</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>GGACC,GGACC,TAACC,AAACA,AGACC,GGACA,TAACA,TGAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>N_peak_44</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GGACC,TAACC,AAACA,AGACC,GGACA,TAACA,TGACC,GGAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>N_peak_45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GAACA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>N_peak_46</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AGACA,GAACT,AAACA,TGACC,TGACA,AGAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>ORF10_peak</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TAACT,TAACT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           loci  DRACH  RGAC  AAGAA  \\\n",
       "0        S_peak     12     3      0   \n",
       "2      S_peak_3      3     1      0   \n",
       "3      S_peak_4     23     7      1   \n",
       "4      S_peak_5      2     0      0   \n",
       "5      S_peak_6      4     1      0   \n",
       "..          ...    ...   ...    ...   \n",
       "163   N_peak_43     35    12      5   \n",
       "164   N_peak_44      7     4      0   \n",
       "165   N_peak_45      1     0      0   \n",
       "166   N_peak_46      5     1      0   \n",
       "167  ORF10_peak      2     0      0   \n",
       "\n",
       "                                              Sequence  \n",
       "0    GGACT,GAACC,AGACT,TGACC,AAACA,AAACT,TAACT,AAAC...  \n",
       "2                               GAACT,TGACA,TGACC,AGAC  \n",
       "3    GAACT,TGACA,GGACT,GGACC,TAACC,TAACA,AGACC,AAAC...  \n",
       "4                                          TAACA,AAACC  \n",
       "5                         GAACT,GGACC,AAACA,TAACA,GGAC  \n",
       "..                                                 ...  \n",
       "163  GGACC,GGACC,TAACC,AAACA,AGACC,GGACA,TAACA,TGAC...  \n",
       "164  GGACC,TAACC,AAACA,AGACC,GGACA,TAACA,TGACC,GGAC...  \n",
       "165                                              GAACA  \n",
       "166                 AGACA,GAACT,AAACA,TGACC,TGACA,AGAC  \n",
       "167                                        TAACT,TAACT  \n",
       "\n",
       "[166 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DRACH = re.compile('[AGT][AG]AC[ACT]') \n",
    "RGAC = re.compile('[AG]GAC') \n",
    "AAGAA = re.compile('AAGAA') \n",
    "\n",
    "def read_fasta(path):\n",
    "    file = open(path)\n",
    "    lines = file.read().splitlines()\n",
    "    ids = [s[1:] for s in lines if '>' in s]\n",
    "    n = [i for i,s in enumerate(lines) if '>' in s]\n",
    "    n.append(len(lines))\n",
    "    sequences = [''.join(lines[i+1:j]) for i,j in zip(n[:-1],n[1:])]\n",
    "    file.close()\n",
    "    fa = dict(zip(ids, sequences))\n",
    "    return fa\n",
    "\n",
    "def find_motifs(sam):\n",
    "    motifs = [[f.split('::')[0], \n",
    "         len(DRACH.findall(sam[f])), \n",
    "         len(RGAC.findall(sam[f])), \n",
    "         len(AAGAA.findall(sam[f])),\n",
    "         ','.join(DRACH.findall(sam[f]) + RGAC.findall(sam[f]) + AAGAA.findall(sam[f]))]\n",
    "        for n, f in enumerate(sam)\n",
    "    ]\n",
    "    df = pd.DataFrame(motifs, columns=[\"loci\",\"DRACH\", \"RGAC\", \"AAGAA\",\"Sequence\"])\n",
    "    return df\n",
    "\n",
    "peak_sequence = read_fasta('merge_peaks.fa')\n",
    "motif_df = find_motifs(peak_sequence)\n",
    "motif_df.replace(motif_df.iloc[1,4], np.nan, inplace=True)\n",
    "\n",
    "motif_df.dropna(subset=[\"Sequence\"], inplace=True)\n",
    "\n",
    "motif_df.to_csv('Results/motif_analysis.txt', sep='\\t')\n",
    "motif_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter some peaks with `DRACH` and `RGAC` motifs for below analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peaks_with_motifs = motif_df[\n",
    "    (motif_df.DRACH > 1) # & (motif_df.DRACH < 8) \n",
    "    &\n",
    "    (motif_df.RGAC > 0)\n",
    "    &\n",
    "    (motif_df.AAGAA > 0)\n",
    "].loci.tolist()\n",
    "len(peaks_with_motifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. m6A/input test of significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have discussed two scenarios with Honi to evaluate p-values for every peak in each samples (I'm following second option):\n",
    "### 1st\n",
    "- In IP samples, count reads mapping to the peak, and all peaks mapping to non-peak regions (i.e. background)\n",
    "- In input, count the same, i.e. reads in the peak and non-peak\n",
    "- that gives you a 2x2 contingency table, then calculate a p-value using Fisher's exact test\n",
    "\n",
    " _'non-peak' = it is total, reads mapping to all peaks_\n",
    "\n",
    "### 2ed\n",
    "- [ctest](https://github.com/lzcyzm/exomePeak/blob/master/R/ctest.R) function from exomepeak. [Here](https://github.com/lzcyzm/exomePeak/blob/master/R/peak.calling.module.R) is how that function is used\n",
    "\n",
    "> `PEAK$loci2peak_merged=.get.peak.from.loci(READS_COUNT,ID,PARAMETERS)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_counts(samples):\n",
    "    '''\n",
    "    Read raw counnt for IN and RIP into a pandas DataFrame    \n",
    "    '''\n",
    "    all_samples = np.concatenate([[N+'_IN',N+'_RIP'] for N in samples]).tolist()\n",
    "    # Read count files as dataframe\n",
    "    df_list = [\n",
    "        pd.read_csv('virus_count/' + file, header=None, sep='\\t', index_col=0) \n",
    "        for file in [N+'.fc' for N in all_samples]\n",
    "    ]\n",
    "    # concatenate them together \n",
    "    data = pd.concat(df_list, axis=1)\n",
    "    data.columns = all_samples\n",
    "    return data\n",
    "\n",
    "\n",
    "def peak_names(samples):\n",
    "    '''\n",
    "    Extract peak names    \n",
    "    '''\n",
    "    peak_names = read_counts(samples).index.tolist()\n",
    "    return peak_names\n",
    "\n",
    "\n",
    "def add_border(plot,sig):\n",
    "    '''\n",
    "    For a given heatmap plot [plot], this function draw rectangles \n",
    "    around an array defined as list in the input indices.  \n",
    "    '''\n",
    "    i,j = sig\n",
    "    plot.add_patch(Rectangle((i, j), 1, 1, fill=False, edgecolor='red', lw=5))\n",
    "\n",
    "    \n",
    "# https://towardsdatascience.com/how-to-create-a-plotly-visualization-and-embed-it-on-websites-517c1a78568b\n",
    "def draw_heatmap(data, borders=None, save=False, name_it='', vmin=None,vmax=None):\n",
    "    '''\n",
    "    Draw/save heatmap plot with option to draw rectangle around given cells \n",
    "    '''\n",
    "    heat_map = sns.heatmap(data,linewidth=2, vmin=vmin,vmax=vmax)\n",
    "    # add borders \n",
    "    if borders: \n",
    "        for sig in borders: add_border (heat_map,sig)\n",
    "    bottom, top = heat_map.get_ylim()\n",
    "    heat_map.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    heat_map.set_yticklabels(heat_map.get_yticklabels(), rotation=0)\n",
    "    if save:\n",
    "        plt.savefig(name_it + '.png')\n",
    "        plt.savefig(name_it + '.pdf')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "Peak_names = peak_names(Samples)\n",
    "Counts = read_counts(Samples)\n",
    "\n",
    "Counts.to_csv('Results/raw_counts.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some `R`! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "# These function implemented from exomePeak R package. \n",
    "\n",
    "ctest <-  function(IP,INPUT,TOTAL_IP,TOTAL_INPUT,FOLD=1,minimal_counts_in_fdr = 10) {\n",
    "  \n",
    "  # input check\n",
    "  if (length(IP) != length(INPUT)) { \n",
    "      stop(\"The IP and INPUT of ctest must be of the same length.\", call. = TRUE, domain = NULL) \n",
    "  }\n",
    "  # replace 0 with 1\n",
    "  IP=pmax(IP,1)\n",
    "  INPUT=pmax(INPUT,1)\n",
    "  \n",
    "  # calculate p\n",
    "  a=TOTAL_IP*FOLD\n",
    "  b=TOTAL_INPUT\n",
    "  p=a/(a+b)\n",
    "  \n",
    "  # get total observation\n",
    "  total=IP+INPUT\n",
    "  \n",
    "  # cdf\n",
    "  log.p=pbinom(IP-1, total, p, lower.tail = FALSE, log.p = TRUE)\n",
    "  \n",
    "  # calculate p  \n",
    "  pvalues=exp(log.p)\n",
    "  \n",
    "  # calculate fdr\n",
    "  log.fdr=log(p.adjust(pvalues, method = \"fdr\"))\n",
    "  \n",
    "  # with significant number of reads only\n",
    "  ID=which( (IP+INPUT) > minimal_counts_in_fdr)\n",
    "  log.fdr_sig=log(p.adjust(pvalues[ID], method = \"fdr\"))\n",
    "  log.fdr[ID]=log.fdr_sig\n",
    "  \n",
    "  # fold enrichment\n",
    "  log.fc=log((pmax(1,IP)/sum(IP))/(pmax(1,INPUT)/sum(INPUT)))\n",
    "  \n",
    "  # output result\n",
    "  PW=list(log.p=log.p,log.fdr=log.fdr,log.fc=log.fc)\n",
    "  return(PW)\n",
    "\n",
    "}\n",
    "\n",
    "peak.calling <- function(READS_COUNT,SAMPLE_ID){\n",
    "    \n",
    "    # check points comparison\n",
    "    IP=READS_COUNT[,paste(SAMPLE_ID,'RIP',sep='_')]\n",
    "    INPUT=READS_COUNT[,paste(SAMPLE_ID,'IN',sep='_')]\n",
    "    \n",
    "    PW = ctest(IP,INPUT,sum(IP),sum(INPUT))\n",
    "    \n",
    "    # output peaks\n",
    "    return(PW)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i Counts,Samples,Peak_names -o RESULTS\n",
    "Samples = unlist(Samples)\n",
    "Peak_names = unlist(Peak_names)\n",
    "\n",
    "RESULTS = list()\n",
    "for (S in Samples){RESULTS[[S]] = peak.calling(Counts,S)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ctest` results for every peaks in every samples are ready to go! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p  = pd.DataFrame([np.array(R[0]) for R in RESULTS], index=Samples,columns=Peak_names)\n",
    "log_fdr= pd.DataFrame([np.array(R[1]) for R in RESULTS], index=Samples,columns=Peak_names)\n",
    "log_fc = pd.DataFrame([np.array(R[2]) for R in RESULTS], index=Samples,columns=Peak_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ob.r.names(RESULTS)) == Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Mutation analysis \n",
    "\n",
    "https://www.datacamp.com/community/tutorials/fuzzy-string-python\n",
    "\n",
    "Levenshtein Distance Equation\n",
    "https://medium.com/@ethannam/understanding-the-levenshtein-distance-equation-for-beginners-c4285a5604f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak sequences as dataframe\n",
    "peak_seq_df = pd.DataFrame(\n",
    "    list(peak_sequence.items()),\n",
    "    columns = ['coordinate','sequence']\n",
    ") \n",
    "peak_seq_df.index = [peak_seq_df.loc[p,'coordinate'].split('::')[0] for p in peak_seq_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WGS sequencing of patient samples as datafram\n",
    "files = glob.glob('virus_WGS/*.fasta')\n",
    "sample_seq_df = pd.DataFrame(columns = ['sequence']) \n",
    "for f in files:\n",
    "    sample = f.replace('virus_WGS/NM-n','').replace('.fasta','')\n",
    "    sample_seq_df.loc[sample] = list(read_fasta(f).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build empty numpy array \n",
    "mutation_mat = np.zeros((\n",
    "    sample_seq_df.shape[0], \n",
    "    peak_seq_df.shape[0]  \n",
    "))\n",
    "\n",
    "# nested for loop to run string matching between peak and sample sequencing\n",
    "for i, sample in enumerate(sample_seq_df['sequence'].to_list() ):\n",
    "    for j,peak in enumerate(peak_seq_df['sequence'].to_list() ):\n",
    "        mutation_mat[i,j] = fuzz.partial_ratio(sample, peak)\n",
    "        \n",
    "# column normalization of partial_ratio score\n",
    "mutation_mat_norm = pp.minmax_scale(mutation_mat, axis=0)\n",
    "\n",
    "mutation_df = pd.DataFrame(\n",
    "    mutation_mat,\n",
    "    index=sample_seq_df.index.to_list(), columns=peak_seq_df.index.to_list()\n",
    ")\n",
    "\n",
    "mutation_norm_df = pd.DataFrame(\n",
    "    mutation_mat_norm,\n",
    "    index=sample_seq_df.index.to_list(), columns=peak_seq_df.index.to_list()\n",
    ")\n",
    "\n",
    "mutation_df.to_csv('Results/mutation_mat_fuzzy_partial_ratio.txt', sep='\\t')\n",
    "mutation_norm_df.to_csv('Results/mutation_mat_norm.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fresh = (100 - mutation_mat) - 30 \n",
    "# fresh_df = pd.DataFrame(\n",
    "#     fresh,\n",
    "#     index=sample_seq_df.index.to_list(), columns=peak_seq_df.index.to_list()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutated_peaks = mutation_norm_df.sum(axis=0) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,5))\n",
    "# draw_heatmap(mutation_norm_df.loc[:,mutated_peaks], )\n",
    "# mutation_norm_df.loc[:,mutated_peaks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(not used scripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of reads:\n",
    "1. Using `samtools` to convert `bam` files to `fastq` files \n",
    "2. Count total number of lines / by 4 as total number of reads "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "virus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash --err error\n",
    "mkdir -p total\n",
    "echo 'sample, reads' > total/virus.txt\n",
    "for f in virus_bam/*bam;\n",
    "\tdo \n",
    "    name=`basename $f`\n",
    "    name=${name/.bam/}\n",
    "    declare -i a=`samtools fastq $f | wc -l`\n",
    "    read=$((a / 4))\n",
    "    echo $name,$read >> total/virus.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "human "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash --err error\n",
    "echo 'sample, reads' > total/human.txt\n",
    "for f in */bam/*.bam; \n",
    "\tdo \n",
    "    name=`basename $f`\n",
    "    name=${name/.bam/}\n",
    "    declare -i a=`samtools fastq $f | wc -l`\n",
    "    read=$((a / 4))\n",
    "    echo $name,$read >> total/human.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ctrl m6A_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash --err error\n",
    "echo 'sample, reads' > total/m6A_neg.txt\n",
    "for f in */int_ctrl/virus/m6A_neg/*bam; \n",
    "\tdo \n",
    "    name=`basename $f`\n",
    "    name=${name/_S[0-9]*/}\n",
    "    name=${name/.bam/}\n",
    "    declare -i a=`samtools fastq $f | wc -l`\n",
    "    read=$((a / 4))\n",
    "    echo $name,$read >> total/m6A_neg.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ctrl m6A_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash --err error\n",
    "echo 'sample, reads' > total/m6A_pos.txt\n",
    "for f in */int_ctrl/virus/m6A_pos/*bam; \n",
    "\tdo \n",
    "    name=`basename $f`\n",
    "    name=${name/_S[0-9]*/}\n",
    "    name=${name/.bam/}\n",
    "    declare -i a=`samtools fastq $f | wc -l`\n",
    "    read=$((a / 4))\n",
    "    echo $name,$read >> total/m6A_pos.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned = ['human','virus','m6A_pos','m6A_neg']\n",
    "total_df = pd.concat([pd.read_csv('total/'+a+'.txt', sep=',', index_col=0).sort_index() for a in aligned],axis=1)\n",
    "total_df.columns = aligned\n",
    "\n",
    "total_df.to_csv('total_reads.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and normalize counts \n",
    "Log normalization of peak counts \n",
    "\n",
    "$$\\log_2 \\dfrac{\n",
    "    \\dfrac{\\text{m6A counts in the peak}}{\\text{m6A total counts}}\n",
    "    }{\n",
    "    \\dfrac{\\text{input counts in the peak}}{\\text{input total counts}}\n",
    "    }\n",
    "    $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def norm_counts(counts, samples, total_reads, norm='l1'):\n",
    "#     all_samples = np.concatenate([[N+'_IN',N+'_RIP'] for N in samples]).tolist()    \n",
    "#     peak_names = counts.index.tolist()\n",
    "#     n_sam = len(all_samples)\n",
    "#     # normalize\n",
    "#     total = total_reads.loc[all_samples,].sum(axis=1)\n",
    "#     total = np.array(total).T\n",
    "#     data = np.array(counts[all_samples]) \n",
    "#     # log2 (RIP in peak / RIP total) / (IN in peak / IN total)\n",
    "#     res = np.log2(\n",
    "#         (\n",
    "#             # RIP / RIP ctrl\n",
    "#             data [:,np.array(range(1,n_sam,2))] \n",
    "#             /\n",
    "#             total[np.array(range(1,n_sam,2))]\n",
    "#         ) / (\n",
    "#             # IN / IN ctrl\n",
    "#             data [:,np.array(range(0,n_sam,2))] \n",
    "#             /\n",
    "#             total[np.array(range(0,n_sam,2))]\n",
    "#         )\n",
    "#     )\n",
    "#     # normalization by samples\n",
    "#     if norm == None:\n",
    "#         res = res\n",
    "#     elif norm == 'min':\n",
    "#         res = pp.minmax_scale(res, feature_range=(0, 1), axis=1)\n",
    "#     elif norm == 'zscore':\n",
    "#         res = stats.zscore(res, axis=0, ddof=1)\n",
    "#     else:\n",
    "#         res = pp.normalize(res, axis=1, norm=norm)\n",
    "#     res_df = pd.DataFrame(data=res, columns=samples, index=peak_names)\n",
    "#     return res_df\n",
    "\n",
    "\n",
    "# Total = pd.read_csv('total_reads.txt', sep = '\\t', index_col=0)  \n",
    "# Norm_counts = norm_counts(Counts, Samples, Total, norm=None)\n",
    "# Norm_counts.to_csv('norm_counts.txt', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
