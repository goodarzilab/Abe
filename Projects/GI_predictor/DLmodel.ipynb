{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCLE Simple autoencoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the model to use later in trianing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import re, sys, os\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import CSVLogger, History\n",
    "from sklearn.preprocessing import LabelEncoder, normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "user = '/rumi/shams/abe/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(user=user, dtype = 'counts'):\n",
    "    t0 = time()\n",
    "    data_folder = user + 'Datasets/CCLE/'\n",
    "    m_rna_counts = data_folder + 'CCLE_RNAseq_genes_counts_20180929.gct.gz'\n",
    "    m_rna_rpkm = data_folder + 'CCLE_RNAseq_genes_rpkm_20180929.gct.gz'\n",
    "    \n",
    "    # select input format \n",
    "    if dtype == 'counts':\n",
    "        m_rna = m_rna_counts\n",
    "    elif dtype == 'rpkm':\n",
    "        m_rna = m_rna_rpkm\n",
    "    \n",
    "    # read raw data\n",
    "    raw_m_rna = pd.read_csv(m_rna, skiprows=2, sep='\\t')\n",
    "\n",
    "    # make meta data dictionary \n",
    "    meta = {'m_rna': raw_m_rna[['Name','Description']],\n",
    "            'cell_lines': raw_m_rna.columns.values.tolist()[2:]}\n",
    "    # normalize\n",
    "    df_m_rna = raw_m_rna.drop(columns=['Name','Description']).to_numpy()\n",
    "    df_m_rna = normalize(X=df_m_rna, axis=0, norm=\"max\")\n",
    "    data = {'df':df_m_rna, 'meta': meta}\n",
    "    return data \n",
    "\n",
    "def simple_autoencoder(df, encoding_dim = 32, test_size=0.10, batch_size = 256, epochs = 50 , model_id='', user=user):\n",
    "    def create_model(X):\n",
    "        # this is our input placeholder\n",
    "        myinput = Input(shape=(X.shape[1],))\n",
    "        # \"encoded\" is the encoded representation of the input\n",
    "        encoded = Dense(encoding_dim*2**2, activation='relu')(myinput)\n",
    "        encoded = Dense(encoding_dim*2, activation='relu')(encoded)\n",
    "        encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "        decoded = Dense(encoding_dim*2, activation='relu')(encoded)\n",
    "        decoded = Dense(encoding_dim*2**2, activation='relu')(decoded)\n",
    "        decoded = Dense(X.shape[1], activation='sigmoid')(decoded)\n",
    "        # \"decoded\" is the lossy reconstruction of the input\n",
    "        decoded = Dense(X.shape[1], activation='sigmoid')(encoded)\n",
    "        # this model maps an input to its reconstruction\n",
    "        autoencoder = Model(myinput, decoded)\n",
    "        # Let's also create a separate encoder model: this model maps an input to its encoded representation\n",
    "        encoder = Model(myinput, encoded)\n",
    "        # As well as the decoder model: create a placeholder for an encoded (32-dimensional) input\n",
    "        encoded_input = Input(shape=(encoding_dim,))\n",
    "        # retrieve the last layer of the autoencoder model\n",
    "        decoder_layer = autoencoder.layers[-1]\n",
    "        # create the decoder model\n",
    "        decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "        autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "        return autoencoder #, encoder, decoder\n",
    "\n",
    "    results_folder = user + 'Projects/GI_predictor/Results/'\n",
    "    file_name = \"CCLE_autoencoder_bs_\"+str(batch_size)+\"_ep_\"+str(epochs)+model_id\n",
    "    # make X and y from df\n",
    "    X = df.T\n",
    "    y = X\n",
    "    X_train, X_test,_,_ = train_test_split(X, X, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # log files \n",
    "    csv_logger = CSVLogger(results_folder + file_name+\".log\")\n",
    "#     history = History()\n",
    "    # make and fit model\n",
    "    model = create_model(X)\n",
    "    model.fit(X_train, X_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            validation_data=(X_test, X_test))\n",
    "\n",
    "#     print(history.keys())\n",
    "    print(\"fitting has just been finished\")\n",
    "    # save the model and encoded-layer output\n",
    "\n",
    "    model.save(filepath=results_folder+file_name+\".h5\")\n",
    "#     layer_name = \"encoded\"\n",
    "#     encoded_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "#     encoded_output = encoded_layer_model.predict(X)\n",
    "#     np.savetxt(X=encoded_output, fname=results_folder + \"ccle_encoded.csv\", delimiter=\",\")\n",
    "\n",
    "    # save the result and prediction value\n",
    "    data_pred = model.predict(X_test, batch_size=batch_size, verbose=2)\n",
    "    np.savetxt(X=X_test, fname=results_folder + \"X_test.\" + file_name+\".csv\", delimiter=\",\")\n",
    "    np.savetxt(X=data_pred[0], fname=results_folder + \"X_pred.\"+file_name+\".csv\", delimiter=\",\")\n",
    "    print(\"prediction process has just been finished\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data()\n",
    "cell_lines = data['meta']['cell_lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 917 samples, validate on 102 samples\n",
      "Epoch 1/50\n",
      "917/917 [==============================] - 2s 2ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 2/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 3/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 4/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 5/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 6/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6931 - val_loss: 0.6930\n",
      "Epoch 7/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6930 - val_loss: 0.6930\n",
      "Epoch 8/50\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.6930 - val_loss: 0.6930\n",
      "Epoch 9/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6930 - val_loss: 0.6930\n",
      "Epoch 10/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6930 - val_loss: 0.6930\n",
      "Epoch 11/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6930 - val_loss: 0.6930\n",
      "Epoch 12/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6929 - val_loss: 0.6929\n",
      "Epoch 13/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6929 - val_loss: 0.6929\n",
      "Epoch 14/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6929 - val_loss: 0.6929\n",
      "Epoch 15/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6929 - val_loss: 0.6929\n",
      "Epoch 16/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6929 - val_loss: 0.6929\n",
      "Epoch 17/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6929 - val_loss: 0.6928\n",
      "Epoch 18/50\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.6928 - val_loss: 0.6928\n",
      "Epoch 19/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6928 - val_loss: 0.6928\n",
      "Epoch 20/50\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.6928 - val_loss: 0.6928\n",
      "Epoch 21/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6928 - val_loss: 0.6928\n",
      "Epoch 22/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6928 - val_loss: 0.6928\n",
      "Epoch 23/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6928 - val_loss: 0.6927\n",
      "Epoch 24/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6927 - val_loss: 0.6927\n",
      "Epoch 25/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6927 - val_loss: 0.6927\n",
      "Epoch 26/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6927 - val_loss: 0.6927\n",
      "Epoch 27/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6927 - val_loss: 0.6927\n",
      "Epoch 28/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6927 - val_loss: 0.6926\n",
      "Epoch 29/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6926 - val_loss: 0.6926\n",
      "Epoch 30/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6926 - val_loss: 0.6926\n",
      "Epoch 31/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6926 - val_loss: 0.6926\n",
      "Epoch 32/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6926 - val_loss: 0.6926\n",
      "Epoch 33/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6926 - val_loss: 0.6926\n",
      "Epoch 34/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6926 - val_loss: 0.6925\n",
      "Epoch 35/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6925 - val_loss: 0.6925\n",
      "Epoch 36/50\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.6925 - val_loss: 0.6925\n",
      "Epoch 37/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6925 - val_loss: 0.6925\n",
      "Epoch 38/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6925 - val_loss: 0.6925\n",
      "Epoch 39/50\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.6925 - val_loss: 0.6925\n",
      "Epoch 40/50\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.6924 - val_loss: 0.6924\n",
      "Epoch 41/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6924 - val_loss: 0.6924\n",
      "Epoch 42/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6924 - val_loss: 0.6924\n",
      "Epoch 43/50\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.6924 - val_loss: 0.6924\n",
      "Epoch 44/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6924 - val_loss: 0.6924\n",
      "Epoch 45/50\n",
      "917/917 [==============================] - 1s 2ms/step - loss: 0.6924 - val_loss: 0.6923\n",
      "Epoch 46/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6923 - val_loss: 0.6923\n",
      "Epoch 47/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6923 - val_loss: 0.6923\n",
      "Epoch 48/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6923 - val_loss: 0.6923\n",
      "Epoch 49/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6923 - val_loss: 0.6923\n",
      "Epoch 50/50\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6923 - val_loss: 0.6923\n",
      "fitting has just been finished\n",
      "prediction process has just been finished\n"
     ]
    }
   ],
   "source": [
    "model = simple_autoencoder(data['df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[385, 'K562_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[i, cell] for i, cell in enumerate(cell_lines) if 'K562' in cell ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[380, 'JURKAT_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[i, cell] for i, cell in enumerate(cell_lines) if 'JURKAT' in cell ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import fisher_exact, spearmanr\n",
    "import plotly as py\n",
    "import plotly.tools as tls\n",
    "from screen import get_SLdataset, get_gene_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GI Scores\n",
    "Load data from [Mapping the Genetic Landscape of Human Cells](https://www.sciencedirect.com/science/article/pii/S0092867418307359?via%3Dihub#mmc2) paper. \n",
    "> [**Table S5.**](https://www.sciencedirect.com/science/article/pii/S0092867418307359?via%3Dihub#mmc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K562: 99.55%\t100128 SLs from 100576 unique gene pairs\n",
      "Jurkat: 99.49%\t75078 SLs from 75466 unique gene pairs \n",
      "done in 54.022702s\n"
     ]
    }
   ],
   "source": [
    "SL_dataset = get_SLdataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data: cBioportal cohorts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st\n",
    "- ### [Acute Myeloid Leukemia (OHSU, Nature 2018)](https://www.cbioportal.org/study?id=aml_ohsu_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = 'cBioPortal/aml_ohsu_2018/' + 'data_RNA_Seq_expression_cpm_Zscores.txt'\n",
    "# ls cBioPortal/aml_ohsu_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f_path,sep='\\t', index_col='Hugo_Symbol', \n",
    "                   na_values ='NA').drop(columns='Entrez_Gene_Id').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gene pairs for **K562** GI pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of patients X 2 = 902 \n",
      "num of gene pairs (Obs.) = 657\n"
     ]
    }
   ],
   "source": [
    "cell_line = 'K562'\n",
    "data_G1, data_G2 = get_gene_pairs(SL_dataset[cell_line], data)\n",
    "X = np.concatenate((    np.array (data_G1.T),    np.array (data_G2.T)))\n",
    "# this is our input:\n",
    "print (f'num of patients X 2 = {X.shape[0]} \\nnum of gene pairs (Obs.) = {X.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gene pairs for **Jurkat** GI pairs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd\n",
    "- ### [Pediatric Acute Lymphoid Leukemia - Phase II (TARGET, 2018)](https://www.cbioportal.org/study?id=all_phase2_target_2018_pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls cBioPortal/all_phase2_target_2018_pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type_of_cancer: bll\n",
      "cancer_study_identifier: all_phase2_target_2018_pub\n",
      "name: Pediatric Acute Lymphoid Leukemia - Phase II (TARGET, 2018)\n",
      "short_name: ALL-Phase II (TARGET, 2018)\n",
      "description: Comprehensive profiling of ALL Phase 2 samples. <p>TARGET data is intended exclusively for biomedical research using pediatric data (i.e., the research objectives cannot be accomplished using data from adults) that focus on the development of more effective treatments, diagnostic tests, or prognostic markers for childhood cancers. Moreover, TARGET data can be used for research relevant to the biology, causes, treatment and late complications of treatment of pediatric cancers, but is not intended for the sole purposes of methods and/or tool development (please see <a href=\"https://ocg.cancer.gov/programs/target/using-target-data\">Using TARGET Data</a> section of the OCG website). If you are interested in using TARGET data for publication or other research purposes, you must follow the <a href=\"https://ocg.cancer.gov/programs/target/target-publication-guidelines\">TARGET Publication Guidelines</a>.</p\n",
      "groups: NCI-TARGET;PUBLIC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# meta data\n",
    "filepath = 'cBioPortal/all_phase2_target_2018_pub/meta_study.txt'\n",
    "with open(filepath) as fp:\n",
    "    print( fp.read() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = 'cBioPortal/all_phase2_target_2018_pub/' + 'data_RNA_Seq_mRNA_median_Zscores.txt'\n",
    "data = pd.read_csv(f_path,sep='\\t', index_col='Hugo_Symbol', \n",
    "                   na_values ='NA', na_filter = True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gene pairs for **K562** GI pairs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gene pairs for **Jurkat** GI pairs:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
