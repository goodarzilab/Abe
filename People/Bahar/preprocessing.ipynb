{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aim:** anlysis of CITE-seq data\n",
    "\n",
    "**Tools**: \n",
    "1. Alignment and count: [`cellranger`](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/what-is-cell-ranger) or [`kallisto | bustools`](https://www.kallistobus.tools/)\n",
    "2. Preprocessing: [`scanpy`](https://scanpy.readthedocs.io/en/stable/) or [`seurat`](https://satijalab.org/seurat/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Alignment and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat kb-count.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat kite.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try `cellranger` instead! (see [this link](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/using/feature-bc-analysis))\n",
    "> The pipeline outputs a unified feature-barcode matrix that contains gene expression counts alongside Feature Barcode counts for each cell barcode. \n",
    "\n",
    "> To enable Feature Barcode analysis, `cellranger count` needs two new inputs:\n",
    "> 1. Libraries CSV is passed to `cellranger count` with the `--libraries` flag, and declares the FASTQ files and library type for each input dataset. In a typical Feature Barcode analysis there will be two input libraries: one for the normal single-cell gene expression reads, and one for the Feature Barcode reads. This argument replaces the `--fastqs` argument.\n",
    "> 2. Feature Reference CSV is passed to `cellranger count` with the `--feature-ref` flag and declares the set of Feature Barcode reagents in use in the experiment. For each unique Feature Barcode used, this file declares a feature name and identifier, the unique Feature Barcode sequence associated with this reagent, and a pattern indicating how to extract the Feature Barcode sequence from the read sequence. See [Feature Barcode Reference](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/using/feature-bc-analysis#feature-ref) for details on how to construct the feature reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Surface protein counts\n",
    "Here we aim to run `kite` and load results into python using `scanpy` library. \n",
    "\n",
    "Main kite workflow didn't work and most of barcodes didn't match (see [here](https://github.com/pachterlab/kite)). So, I'm trying https://www.kallistobus.tools/tutorials/kb_kite/python/kb_kite.html -->\n",
    "\n",
    "https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/using/feature-bc-analysis#feature-ref\n",
    "\n",
    "> __Feature Barcode Extraction Pattern__\n",
    "\n",
    "> The `pattern` field of the feature reference defines how to locate the Feature Barcode within a read. The Feature Barcode may appear at a known offset with respect to the start or end of the read or may appear at a fixed position relative to a known anchor sequence. The pattern column can be made up of a combination of these elements:\n",
    "\n",
    "> - **5P**: denotes the beginning of the read sequence. May appear 0 or 1 times, and must be at the beginning of the pattern. Only 5P or 3P may appear, not both. (^ may be used instead of 5P.)\n",
    "> - **3P**: denotes the end of the read sequence. May appear 0 or 1 times, and must be at the end of the pattern. (\\$ may be used instead of 3P.)\n",
    "> - **N**: denotes an arbitrary base.\n",
    "> - **A, C, G, T**: denotes a fixed base that must match the read sequence exactly.\n",
    "> - **(BC)**: denotes the Feature Barcode sequence as specified in the sequence column of the feature reference. Must appear exactly once in the pattern.\n",
    "\n",
    "> Any constant sequences made up of A, C, G and T in the pattern must match exactly in the read sequence. Any N in the pattern is allowed to match a single arbitrary base. A modest number of fixed bases should be used to minimize the chance of a sequencing error disrupting the match. The fixed sequence should also be long enough to uniquely identify the position of the Feature Barcode. For feature types that require an non-N anchor, we recommend 12bp-20bp of constant sequence. The extracted Feature Barcode sequences are corrected up to a Hamming distance of 1 using the 10x barcode correction algorithm that is used to correct cell barcodes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,name,read,pattern,sequence,feature_type\r",
      "\r\n",
      "CD45,CD45_TotalSeqB,R2,5PNNNNNNNNNN(BC)NNNNNNNNN,TGGCTATGGAGCAGA,Antibody Capture\r",
      "\r\n",
      "CD3,CD3_TotalSeqB,R2,5PNNNNNNNNNN(BC)NNNNNNNNN,GTATGTCCGCTCGAT,Antibody Capture\r",
      "\r\n",
      "CD8a,CD8a_TotalSeqB,R2,5PNNNNNNNNNN(BC)NNNNNNNNN,TACCCGTAATAGCGT,Antibody Capture\r",
      "\r\n",
      "CD4,CD4_TotalSeqB,R2,5PNNNNNNNNNN(BC)NNNNNNNNN,AACAAGACCCTTGAG,Antibody Capture\r",
      "\r\n",
      "CD14,CD14_TotalSeqB,R2,5PNNNNNNNNNN(BC)NNNNNNNNN,AACCAACAGTCACGT,Antibody Capture\r",
      "\r\n",
      "CD19,CD19_TotalSeqB,R2,5PNNNNNNNNNN(BC)NNNNNNNNN,ATCAGCCATGTCAGT,Antibody Capture\r",
      "\r\n",
      "CD11c,CD11c_TotalSeqB,R2,5PNNNNNNNNNN(BC)NNNNNNNNN,GTTATGGACGCTTGC,Antibody Capture\r",
      "\r\n",
      "PDL1,PDL1_TotalSeqB,R2,5PNNNNNNNNNN(BC)NNNNNNNNN,TCGATTCCACCAACT,Antibody Capture\r",
      "\r\n",
      "TIM3,TIM3_TotalSeqB,R2,5PNNNNNNNNNN(BC)NNNNNNNNN,ATTGGCACTCAGATG,Antibody Capture\r",
      "\r\n",
      "CTLA4,CTLA4_TotalSeqB,R2,5PNNNNNNNNNN(BC)NNNNNNNNN,AGTGTTTGTCCTGGT,Antibody Capture"
     ]
    }
   ],
   "source": [
    "cat feature_ref.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating the CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# import os \n",
    "# import itertools\n",
    "# from glob import glob\n",
    "\n",
    "# # PWD='/rumi/shams/abe/People/Bahar'\n",
    "# PWD='/data_gilbert/home/aarab/People/Bahar'\n",
    "\n",
    "# fastqs = sorted([(PWD+'/fastq/',f.split('_')[0]) for f in map(os.path.basename, glob(\"fastq/*R1*\"))])\n",
    "\n",
    "# library_types = [j for i in list(itertools.repeat(['Gene Expression','Antibody Capture'], 8)) for j in i]\n",
    "\n",
    "# library = pd.DataFrame({\n",
    "#     'fastqs': [path for path,_ in fastqs],\n",
    "#     'sample': [sample for _,sample in fastqs],\n",
    "#     'library_type': library_types})\n",
    "\n",
    "# library.to_csv('library.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts/101.csv\r\n",
      "fastqs,sample,library_type\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,101-GE,Gene Expression\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,101-SP,Antibody Capture\r\n",
      "________________________________________________\r\n",
      "counts/103.csv\r\n",
      "fastqs,sample,library_type\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,103-GE,Gene Expression\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,103-SP,Antibody Capture\r\n",
      "________________________________________________\r\n",
      "counts/104.csv\r\n",
      "fastqs,sample,library_type\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,104-GE,Gene Expression\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,104-SP,Antibody Capture\r\n",
      "________________________________________________\r\n",
      "counts/105.csv\r\n",
      "fastqs,sample,library_type\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,105-GE,Gene Expression\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,105-SP,Antibody Capture\r\n",
      "________________________________________________\r\n",
      "counts/106.csv\r\n",
      "fastqs,sample,library_type\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,106-GE,Gene Expression\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,106-SP,Antibody Capture\r\n",
      "________________________________________________\r\n",
      "counts/108.csv\r\n",
      "fastqs,sample,library_type\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,108-GE,Gene Expression\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,108-SP,Antibody Capture\r\n",
      "________________________________________________\r\n",
      "counts/109.csv\r\n",
      "fastqs,sample,library_type\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,109-GE,Gene Expression\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,109-SP,Antibody Capture\r\n",
      "________________________________________________\r\n",
      "counts/112.csv\r\n",
      "fastqs,sample,library_type\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,112-GE,Gene Expression\r\n",
      "/data_gilbert/home/aarab/People/Bahar/fastq/,112-SP,Antibody Capture\r\n",
      "________________________________________________\r\n"
     ]
    }
   ],
   "source": [
    "!for f in counts/*csv; do echo $f; cat $f; echo \"________________________________________________\"; done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "- https://scanpy-tutorials.readthedocs.io/en/latest/cite-seq/pbmc5k.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load cellranger results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.7.2 anndata==0.7.6 umap==0.5.1 numpy==1.19.1 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.9.6 louvain==0.7.0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scanpy.external as sce\n",
    "import anndata as ad\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "sc.settings.verbosity = 1             # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor='white')\n",
    "\n",
    "sc.logging.print_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/21884271/warning-about-too-many-open-figures\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.techcoil.com/blog/how-to-save-and-load-objects-to-and-from-file-in-python-via-facilities-from-the-pickle-module/\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(adata):\n",
    "    \n",
    "    adata.var_names_make_unique()\n",
    "    # remove doublet\n",
    "    sce.pp.scrublet(adata)\n",
    "    adata  = adata[adata.obs.doublet_score < adata.uns['scrublet']['threshold']]\n",
    "\n",
    "    # Basic filtering:\n",
    "    adata.layers[\"counts\"] = adata.X.copy()\n",
    "    sc.pp.filter_genes(adata, min_counts=1)\n",
    "    \n",
    "    return adata\n",
    "\n",
    "#     sc.pp.filter_genes(adata, min_cells=10)\n",
    "#     sc.pp.filter_cells(adata, min_genes=150)\n",
    "#     # Identify highly-variable genes.\n",
    "#     sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "#     adata.raw = adata\n",
    "#     # Actually do the filtering\n",
    "#     adata = adata[:, adata.var.highly_variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label samples\n",
    "\n",
    "<!-- https://www.kallistobus.tools/tutorials/kb_aggregate/python/kb_aggregating_count_matrices.html -->\n",
    "\n",
    "**Experimetal design**\n",
    "\n",
    "> 2 biological replicates per condition\n",
    "> - 101, 103 --> Nuj selected\n",
    "> - 104,105 --> Balb selected\n",
    "> - 108,106 --> Rag selected\n",
    "> - 109,112 --> NSG selected\n",
    "<!-- > each biological replicate was extracted from mice and ran on 10x on different days\n",
    "so:\n",
    "> - 101, 104,108,109 were extracted, processed loaded on 10x chromium on 8/16/21\n",
    "> - 103, 105,106,112 were extracted, processed loaded on 10x chromium on 8/17/21\n",
    "> The library preparation for all 8 samples was done simultaneously. Two libraries were generated per sample:\n",
    ">- GE: gene expression library (RNA fraction)\n",
    ">- SP: surface protein library (citeseq fraction)\n",
    "\n",
    "> therefore I had total of 16 libraries submitted for sequencing.\n",
    "\n",
    "> The ratio of SP/GE libraries were 1:5 in the final sample pool.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "Nuj-rep1 counts/101/outs/filtered_feature_bc_matrix.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "/rumi/shams/abe/anaconda3/envs/sc-analysis/lib/python3.7/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically set threshold at doublet score = 0.34\n",
      "Detected doublet rate = 1.1%\n",
      "Estimated detectable doublet fraction = 28.4%\n",
      "Overall doublet rate:\n",
      "\tExpected   = 5.0%\n",
      "\tEstimated  = 3.8%\n",
      "__________________________________________________\n",
      "Nuj-rep2 counts/103/outs/filtered_feature_bc_matrix.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "/rumi/shams/abe/anaconda3/envs/sc-analysis/lib/python3.7/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically set threshold at doublet score = 0.36\n",
      "Detected doublet rate = 0.7%\n",
      "Estimated detectable doublet fraction = 18.6%\n",
      "Overall doublet rate:\n",
      "\tExpected   = 5.0%\n",
      "\tEstimated  = 3.7%\n",
      "__________________________________________________\n",
      "Balb-rep1 counts/104/outs/filtered_feature_bc_matrix.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "/rumi/shams/abe/anaconda3/envs/sc-analysis/lib/python3.7/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically set threshold at doublet score = 0.52\n",
      "Detected doublet rate = 0.4%\n",
      "Estimated detectable doublet fraction = 19.2%\n",
      "Overall doublet rate:\n",
      "\tExpected   = 5.0%\n",
      "\tEstimated  = 2.2%\n",
      "__________________________________________________\n",
      "Balb-rep2 counts/105/outs/filtered_feature_bc_matrix.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "/rumi/shams/abe/anaconda3/envs/sc-analysis/lib/python3.7/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically set threshold at doublet score = 0.42\n",
      "Detected doublet rate = 0.6%\n",
      "Estimated detectable doublet fraction = 19.8%\n",
      "Overall doublet rate:\n",
      "\tExpected   = 5.0%\n",
      "\tEstimated  = 3.1%\n",
      "__________________________________________________\n",
      "Rag-rep1 counts/106/outs/filtered_feature_bc_matrix.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "/rumi/shams/abe/anaconda3/envs/sc-analysis/lib/python3.7/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically set threshold at doublet score = 0.42\n",
      "Detected doublet rate = 0.5%\n",
      "Estimated detectable doublet fraction = 16.7%\n",
      "Overall doublet rate:\n",
      "\tExpected   = 5.0%\n",
      "\tEstimated  = 2.9%\n",
      "__________________________________________________\n",
      "Rag-rep2 counts/108/outs/filtered_feature_bc_matrix.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "/rumi/shams/abe/anaconda3/envs/sc-analysis/lib/python3.7/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically set threshold at doublet score = 0.51\n",
      "Detected doublet rate = 0.5%\n",
      "Estimated detectable doublet fraction = 19.4%\n",
      "Overall doublet rate:\n",
      "\tExpected   = 5.0%\n",
      "\tEstimated  = 2.8%\n",
      "__________________________________________________\n",
      "NSG-rep1 counts/109/outs/filtered_feature_bc_matrix.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "/rumi/shams/abe/anaconda3/envs/sc-analysis/lib/python3.7/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically set threshold at doublet score = 0.33\n",
      "Detected doublet rate = 1.4%\n",
      "Estimated detectable doublet fraction = 39.0%\n",
      "Overall doublet rate:\n",
      "\tExpected   = 5.0%\n",
      "\tEstimated  = 3.7%\n",
      "__________________________________________________\n",
      "NSG-rep2 counts/112/outs/filtered_feature_bc_matrix.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "/rumi/shams/abe/anaconda3/envs/sc-analysis/lib/python3.7/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically set threshold at doublet score = 0.26\n",
      "Detected doublet rate = 2.0%\n",
      "Estimated detectable doublet fraction = 38.9%\n",
      "Overall doublet rate:\n",
      "\tExpected   = 5.0%\n",
      "\tEstimated  = 5.1%\n",
      "CPU times: user 5min 21s, sys: 12.4 s, total: 5min 34s\n",
      "Wall time: 52.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "samples = [\n",
    "    'Nuj-rep1','Nuj-rep2',\n",
    "    'Balb-rep1','Balb-rep2',\n",
    "    'Rag-rep1','Rag-rep2',\n",
    "    'NSG-rep1','NSG-rep2'\n",
    "]\n",
    "\n",
    "data = {}\n",
    "for sam, file in zip(samples, sorted(glob('counts/*/outs/filtered_feature_bc_matrix.h5'))):\n",
    "    data[sam] = {}\n",
    "    print ('_'*50)\n",
    "    print (sam, file)\n",
    "    \n",
    "    adata = sc.read_10x_h5(file, gex_only=False)\n",
    "    adata = preprocessing(adata)\n",
    "    \n",
    "    data[sam]['main'] = adata\n",
    "    del adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -pv preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'preprocessing/rawcounts.pkl'\n",
    "\n",
    "save_obj(data, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1292M preprocessing/rawcounts.pkl\r\n"
     ]
    }
   ],
   "source": [
    "ls -s --block-size=M preprocessing/rawcounts.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'preprocessing/rawcounts.pkl'\n",
    "data = load_obj(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic clustering \n",
    "Annotate data based on mRNA expression and surface protein abundance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(adata,lognorm=True,n_neighbor=30,res=None):\n",
    "    if lognorm: \n",
    "        sc.pp.log1p(adata)\n",
    "    sc.pp.pca(adata)\n",
    "    sc.pp.neighbors(adata, n_neighbors=n_neighbor)   # why can't we just work with the default neighbors?\n",
    "    sc.tl.umap(adata)\n",
    "    sc.tl.leiden(adata,resolution=res)\n",
    "\n",
    "\n",
    "# def join_graphs_max(g1: \"sparse.spmatrix\", g2: \"sparse.spmatrix\"):\n",
    "#     \"\"\"Take the maximum edge value from each graph.\"\"\"\n",
    "#     out = g1.copy()\n",
    "#     mask = g1 < g2\n",
    "#     out[mask] = g2[mask]\n",
    "#     return out\n",
    "# \n",
    "#     adata.obsp[\"connectivities\"] = join_graphs_max(adata.obsp[\"rna_connectivities\"], adata.obsp[\"protein_connectivities\"])\n",
    "#     sc.pp.neighbors(adata, n_neighbors=30)   # why can't we just work with the default neighbors?\n",
    "#     sc.tl.leiden(adata, key_added=\"joint_leiden\")\n",
    "#     sc.tl.umap(adata)\n",
    "\n",
    "def annotate_rna_protein(adata):\n",
    "    \n",
    "    protein = adata[:, adata.var[\"feature_types\"] == \"Antibody Capture\"].copy()\n",
    "    \n",
    "    clustering(protein)\n",
    "    \n",
    "    protein.var.set_index('gene_ids',inplace=True)    \n",
    "    adata.obs = pd.concat([adata.obs,protein.to_df()],axis=1) \n",
    "    \n",
    "    print ('protein clustering is done!')\n",
    "    \n",
    "    rna = adata[:, adata.var[\"feature_types\"] == \"Gene Expression\"].copy()\n",
    "    clustering(rna)\n",
    "\n",
    "    print ('RNA clustering is done!')\n",
    "\n",
    "    odata = rna.copy()\n",
    "    \n",
    "    odata.obsm[\"protein_umap\"] = protein.obsm[\"X_umap\"]\n",
    "    odata.obs[\"protein_leiden\"] = protein.obs[\"leiden\"]\n",
    "    odata.obsp[\"protein_connectivities\"] = protein.obsp[\"connectivities\"].copy()\n",
    "\n",
    "    odata.obsm[\"rna_umap\"] = rna.obsm[\"X_umap\"]\n",
    "    del odata.obs[\"leiden\"]\n",
    "    odata.obs[\"rna_leiden\"] = rna.obs[\"leiden\"]\n",
    "    odata.obsp[\"rna_connectivities\"] = rna.obsp[\"connectivities\"].copy()\n",
    "    \n",
    "    return odata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "for sample in data:\n",
    "    print (sample)\n",
    "    data[sample]['main'] = annotate_rna_protein(data[sample]['main'])\n",
    "    # Save `adata`s to file\n",
    "    data[sample]['main'].write(f'preprocessing/{sample}.h5ad.gz',compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw UMAP plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNuj-rep1\n",
      "\u001b[1mNuj-rep2\n",
      "\u001b[1mBalb-rep1\n",
      "\u001b[1mBalb-rep2\n",
      "\u001b[1mRag-rep1\n",
      "\u001b[1mRag-rep2\n",
      "\u001b[1mNSG-rep1\n",
      "\u001b[1mNSG-rep2\n",
      "CPU times: user 11 s, sys: 460 ms, total: 11.4 s\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from matplotlib import pyplot as plot\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "pdf_pages = PdfPages('figures/umap.pdf')\n",
    "\n",
    "# The PDF document\n",
    "for sample in data:\n",
    "    adata = data[sample]['main'].copy()\n",
    "\n",
    "    # Create a figure instance (ie. a new page)\n",
    "    fig = plot.figure(dpi=300)\n",
    "\n",
    "    # Plot whatever you wish to plot\n",
    "    print ('\\033[1m' + sample)\n",
    "    fig = sc.pl.embedding(adata, basis='rna_umap',color=adata.obs.columns[2:], size=10,show=False,return_fig=True)\n",
    "    fig.suptitle(sample +'\\n'+str(adata.shape[0])+' cells, '+str(adata.shape[1])+' genes', fontsize=20)\n",
    "    \n",
    "    fig.set_size_inches(18.5, 10.5) # https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib\n",
    "    \n",
    "    # Done with the page\n",
    "    pdf_pages.savefig(fig)\n",
    "    plt.close(fig)    \n",
    "#     del adata\n",
    "    \n",
    "# Write the PDF document to the disk\n",
    "pdf_pages.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Huge heatmap!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n"
     ]
    }
   ],
   "source": [
    "mergedadata_2 = ad.AnnData(\n",
    "        X=mergedadata.X,\n",
    "        obs=mergedadata.obs.loc[:,[\"CD45\",\"CD3\",\"CD8a\",\"CD4\",\"CD14\",\"CD19\",\"CD11c\",\"PDL1\",\"TIM3\",\"CTLA4\",\"dataset\"]]\n",
    "    )\n",
    "\n",
    "mergedadata_2.var.index = mergedadata.var.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering(mergedadata_2,lognorm=False,n_neighbor=10,res=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: saving figure to file figures/violin_mRNA.pdf\n"
     ]
    }
   ],
   "source": [
    "sc.pl.violin(mergedadata_2, mergedadata_2.obs.columns[:-2], groupby='leiden',save='_mRNA.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.\n",
      "WARNING: saving figure to file figures/heatmap.pdf\n"
     ]
    }
   ],
   "source": [
    "sc.pl.heatmap(mergedadata_2, mergedadata_2.obs.columns[:-2], groupby='leiden', dendrogram=True,save='.pdf',figsize=(5,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: saving figure to file figures/umap_dataset.pdf\n"
     ]
    }
   ],
   "source": [
    "sc.pl.umap(mergedadata_2,color='dataset',save='_dataset.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCD45\n",
      "\u001b[1mCD3\n",
      "\u001b[1mCD8a\n",
      "\u001b[1mCD4\n",
      "\u001b[1mCD14\n",
      "\u001b[1mCD19\n",
      "\u001b[1mCD11c\n",
      "\u001b[1mPDL1\n",
      "\u001b[1mTIM3\n",
      "\u001b[1mCTLA4\n"
     ]
    }
   ],
   "source": [
    "# # The PDF document\n",
    "pdf_pages = PdfPages('figures/violin_cite.pdf')\n",
    "\n",
    "for cite in mergedadata_2.obs.columns[:-2]:\n",
    "    # Create a figure instance (ie. a new page)\n",
    "    fig = plot.figure(figsize=(12, 6), dpi=100)\n",
    "\n",
    "    # Plot whatever you wish to plot\n",
    "    print ('\\033[1m' + cite)\n",
    "    ax = plt.subplot()\n",
    "    sc.pl.violin(mergedadata_2, cite, groupby='leiden',stripplot=False,ax=ax,rotation=90)\n",
    "    # Done with the page\n",
    "    pdf_pages.savefig(fig)\n",
    "    \n",
    "# Write the PDF document to the disk\n",
    "pdf_pages.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: saving figure to file figures/stacked_violin_mRNA.pdf\n"
     ]
    }
   ],
   "source": [
    "sc.pl.stacked_violin(\n",
    "    mergedadata_2,\n",
    "    mergedadata_2.obs.columns[:-2],\n",
    "    groupby='leiden',\n",
    "    title='mRNA Clusters',\n",
    "    save='mRNA.pdf',\n",
    "    dendrogram=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# find gene markers in the 'dataset' group.\n",
    "sc.tl.rank_genes_groups(mergedadata_2, 'leiden', method='wilcoxon', n_genes=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: saving figure to file figures/heatmap_rank_genes_groups_leiden.pdf\n"
     ]
    }
   ],
   "source": [
    "sc.pl.rank_genes_groups_heatmap(mergedadata_2, n_genes=3, use_raw=False, vmin=-3, vmax=3, show_gene_labels=True,cmap='bwr',save='_rank_genes_groups_leiden.pdf',figsize=(30,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import altair as alt\n",
    "# from functools import partial\n",
    "\n",
    "# alt.renderers.enable(\"png\")\n",
    "# alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# def embedding_chart(df: pd.DataFrame, coord_pat: str, *, size=5) -> alt.Chart:\n",
    "#     \"\"\"Make schema for coordinates, like sc.pl.embedding.\"\"\"\n",
    "#     x, y = df.columns[df.columns.str.contains(coord_pat)]\n",
    "#     return (\n",
    "#         alt.Chart(plotdf, height=300, width=300)\n",
    "#         .mark_circle(size=size)\n",
    "#         .encode(\n",
    "#             x=alt.X(x, axis=None),\n",
    "#             y=alt.Y(y, axis=None),\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# def umap_chart(df: pd.DataFrame, **kwargs) -> alt.Chart:\n",
    "#     \"\"\"Like sc.pl.umap, but just the coordinates.\"\"\"\n",
    "#     return embedding_chart(df, \"umap\", **kwargs)\n",
    "\n",
    "# def encode_color(c: alt.Chart, col: str, *, qdomain=(0, 1), scheme: str = \"lightgreyred\") -> alt.Chart:\n",
    "#     \"\"\"Add colors to an embedding plot schema.\"\"\"\n",
    "#     base = c.properties(title=col)\n",
    "#     if pd.api.types.is_categorical(c.data[col]):\n",
    "#         return base.encode(color=col)\n",
    "#     else:\n",
    "#         return base.encode(\n",
    "#             color=alt.Color(\n",
    "#                 col,\n",
    "#                 scale=alt.Scale(\n",
    "#                     scheme=scheme,\n",
    "#                     clamp=True,\n",
    "#                     domain=list(c.data[col].quantile(qdomain)),\n",
    "#                     nice=True,\n",
    "#                 )\n",
    "#             )\n",
    "#         )\n",
    "#     plotdf = sc.get.obs_df(\n",
    "#         rna,\n",
    "#         obsm_keys=[(\"X_umap\", i) for i in range(2)] + [(\"protein\", i) for i in rna.obsm[\"protein\"].columns]\n",
    "#     )\n",
    "\n",
    "#     fig = (\n",
    "#         alt.concat(\n",
    "#             *map(partial(encode_color, umap_chart(plotdf), qdomain=(0, .95)), plotdf.columns[3:]),\n",
    "#             columns=2\n",
    "#         )\n",
    "#         .resolve_scale(color='independent')\n",
    "#         .configure_axis(grid=True)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocessing(adata):\n",
    "#     # Basic filtering:\n",
    "#     sc.pp.filter_genes(adata, min_cells=10)\n",
    "#     sc.pp.filter_cells(adata, min_genes=150)\n",
    "#     # annotate the group of mitochondrial genes as 'mt'\n",
    "#     adata.var['mt'] = adata.var.index.str.startswith('MT-')  \n",
    "#     # Remove cells that have too many mitochondrial genes expressed or too many total counts:\n",
    "#     sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "#     adata = adata[adata.obs.n_genes_by_counts < 2500, :]\n",
    "#     adata = adata[adata.obs.pct_counts_mt < 5, :]\n",
    "#     # Total-count normalize (library-size correct) the data matrix \n",
    "#     # ð— to 10,000 reads per cell, so that counts become comparable among cells.\n",
    "#     sc.pp.normalize_per_cell(adata)\n",
    "#     # Logarithmize the data:\n",
    "#     sc.pp.log1p(adata)\n",
    "#     # Identify highly-variable genes.\n",
    "#     sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "#     adata.raw = adata\n",
    "#     # Actually do the filtering\n",
    "#     adata = adata[:, adata.var.highly_variable]\n",
    "#     # Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. \n",
    "#     # Scale the data to unit variance.\n",
    "#     sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt'])\n",
    "#     # Scale each gene to unit variance. Clip values exceeding standard deviation 10.\n",
    "#     sc.pp.scale(adata, max_value=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A zip file of the three MatrixMarket files (.mtx, .mtx_cols, .mtx_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from zipfile import ZipFile\n",
    "# # https://thispointer.com/python-how-to-create-a-zip-archive-from-multiple-files-or-directory/\n",
    "# def write_adata(adata,name):\n",
    "#     adata.obs.to_csv(f'{name}.mtx_rows.gz',compression='gzip')\n",
    "#     adata.var.to_csv(f'{name}.mtx_cols.gz',compression='gzip')\n",
    "#     adata.to_df().to_csv(f'{name}.mtx.gz', compression='gzip')\n",
    "\n",
    "#     # create a ZipFile object\n",
    "#     zipObj = ZipFile(f'{name}.zip', 'w')\n",
    "#     # Add multiple files to the zip\n",
    "#     zipObj.write(f'{name}.mtx_rows.gz')\n",
    "#     zipObj.write(f'{name}.mtx_cols.gz')\n",
    "#     zipObj.write(f'{name}.mtx.gz')\n",
    "#     # close the Zip File\n",
    "#     zipObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_adata(mix, 'preprocessing/mix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sc-analysis]",
   "language": "python",
   "name": "conda-env-sc-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
